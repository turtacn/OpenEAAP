# OpenEAAP AI Data å…¨æ™¯å›¾ä¸å‚è€ƒæ¶æ„

åŸºäºOpenEAAPé¡¹ç›®çš„å®é™…æ¶æ„ï¼Œå°†ä»**å‚è€ƒæ¨¡å‹ï¼ˆRMï¼‰**ã€**å‚è€ƒæ¶æ„ï¼ˆRAï¼‰**å’Œ**å‚è€ƒå®ç°ï¼ˆRIï¼‰**ä¸‰ä¸ªç»´åº¦ï¼Œä¸ºæ‚¨å‘ˆç°AI Dataçš„å®Œæ•´å…¨æ™¯å›¾ã€‚

## ä¸€ã€AI Data å‚è€ƒæ¨¡å‹ï¼ˆRM - Reference Modelï¼‰

### 1.1 æ ¸å¿ƒèƒ½åŠ›æ¨¡å‹

OpenEAAPé‡‡ç”¨**äº”å¤§èƒ½åŠ›ä¸­å°**æ¶æ„ï¼Œå…¶ä¸­**DIKFï¼ˆData Intelligence & Knowledge Fabricï¼‰æ•°æ®æ™ºèƒ½ä¸çŸ¥è¯†ç¼–ç»‡å¹³å°**æ˜¯AI Dataèƒ½åŠ›çš„æ ¸å¿ƒæ‰¿è½½è€… [1](#0-0) ã€‚

```mermaid
graph TB
    subgraph "AI Data èƒ½åŠ›å…¨æ™¯"
        subgraph "æ•°æ®é‡‡é›†å±‚ Data Ingestion"
            DI1["å®‰å…¨æ—¥å¿—æ•°æ®<br/>Security Logs"]
            DI2["ä¼ä¸šæ–‡æ¡£æ•°æ®<br/>Enterprise Documents"]
            DI3["ä¸šåŠ¡åˆ†ææ•°æ®<br/>Business Analytics"]
            DI4["ç»“æ„åŒ–æ•°æ®<br/>Structured Data"]
            DI5["åŠç»“æ„åŒ–æ•°æ®<br/>Semi-structured Data"]
        end
        
        subgraph "æ•°æ®å¤„ç†å±‚ Data Processing"
            DP1["è§£æå™¨ Parser<br/>å¤šæ ¼å¼æ”¯æŒ"]
            DP2["åˆ†å—å™¨ Chunker<br/>æ™ºèƒ½åˆ‡åˆ†"]
            DP3["å‘é‡åŒ– Embedding<br/>è¯­ä¹‰è¡¨ç¤º"]
            DP4["PIIæ£€æµ‹ä¸è„±æ•<br/>Privacy Protection"]
        end
        
        subgraph "æ•°æ®å­˜å‚¨å±‚ Data Storage"
            DS1["PostgreSQL<br/>å…³ç³»å‹æ•°æ®"]
            DS2["Milvus/Qdrant<br/>å‘é‡æ•°æ®"]
            DS3["Neo4j<br/>çŸ¥è¯†å›¾è°±"]
            DS4["InfluxDB<br/>æ—¶åºæ•°æ®"]
            DS5["MinIO/S3<br/>å¯¹è±¡å­˜å‚¨"]
        end
        
        subgraph "æ•°æ®æ£€ç´¢å±‚ Data Retrieval"
            DR1["å‘é‡æ£€ç´¢<br/>Vector Search"]
            DR2["å…³é”®è¯æ£€ç´¢<br/>Keyword Search"]
            DR3["çŸ¥è¯†å›¾è°±æ£€ç´¢<br/>Graph Search"]
            DR4["æ··åˆæ£€ç´¢<br/>Hybrid Retrieval"]
        end
        
        subgraph "æ•°æ®æ²»ç†å±‚ Data Governance"
            DG1["æ•°æ®è¡€ç¼˜<br/>Data Lineage"]
            DG2["æ•æ„Ÿåº¦æ ‡è®°<br/>Sensitivity Marking"]
            DG3["ç‰ˆæœ¬ç®¡ç†<br/>Version Control"]
            DG4["è®¿é—®æ§åˆ¶<br/>Access Control"]
        end
        
        subgraph "æ•°æ®åé¦ˆå±‚ Data Feedback"
            DF1["åé¦ˆæ”¶é›†<br/>Feedback Collection"]
            DF2["åœ¨çº¿å­¦ä¹ <br/>Online Learning"]
            DF3["æ•°æ®ä¼˜åŒ–<br/>Data Optimization"]
            DF4["æŒç»­è¿­ä»£<br/>Continuous Iteration"]
        end
    end
    
    DI1 & DI2 & DI3 & DI4 & DI5 --> DP1 & DP2 & DP3 & DP4
    DP1 & DP2 & DP3 & DP4 --> DS1 & DS2 & DS3 & DS4 & DS5
    DS1 & DS2 & DS3 & DS4 & DS5 --> DR1 & DR2 & DR3 & DR4
    DG1 & DG2 & DG3 & DG4 -.æ²»ç†.-> DP1 & DS1 & DR1
    DR1 & DR2 & DR3 & DR4 --> DF1
    DF1 --> DF2 --> DF3 --> DF4
    DF4 -.ä¼˜åŒ–è¿­ä»£.-> DP1
```

### 1.2 æ•°æ®ç±»å‹å¤„ç†èƒ½åŠ›çŸ©é˜µ

æ ¹æ®OpenEAAPçš„æ¶æ„è®¾è®¡ï¼Œé’ˆå¯¹ä¸åŒæ•°æ®ç±»å‹æä¾›ä¸“é—¨çš„å¤„ç†èƒ½åŠ› [2](#0-1) ï¼š

| æ•°æ®ç±»å‹ | å¤„ç†ç­–ç•¥ | å­˜å‚¨æ–¹æ¡ˆ | æ£€ç´¢æ–¹å¼ | åº”ç”¨åœºæ™¯ |
|---------|---------|---------|---------|---------|
| **å®‰å…¨æ—¥å¿—æ•°æ®** | è§£æ â†’ ç»“æ„åŒ– â†’ æ—¶åºå­˜å‚¨ | InfluxDB + PostgreSQL | æ—¶é—´èŒƒå›´ + å…³é”®è¯ | SOCå¨èƒåˆ†æã€å¼‚å¸¸æ£€æµ‹ |
| **ä¼ä¸šæ–‡æ¡£æ•°æ®** | è§£æ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ PIIè„±æ• | PostgreSQL + Milvus + MinIO | å‘é‡æ£€ç´¢ + æ··åˆæ£€ç´¢ | æ™ºèƒ½æ–‡æ¡£é—®ç­”ã€çŸ¥è¯†ç®¡ç† |
| **ä¸šåŠ¡åˆ†ææ•°æ®** | èšåˆ â†’ æŒ‡æ ‡æå– â†’ å›¾è°±æ„å»º | PostgreSQL + Neo4j | SQL + å›¾æŸ¥è¯¢ | ä¸šåŠ¡æ´å¯Ÿã€å…³è”åˆ†æ |
| **ç»“æ„åŒ–æ•°æ®** | SchemaéªŒè¯ â†’ ç´¢å¼•æ„å»º | PostgreSQL | SQLæŸ¥è¯¢ | äº‹åŠ¡å¤„ç†ã€æŠ¥è¡¨ç”Ÿæˆ |
| **åŠç»“æ„åŒ–æ•°æ®** | JSON/XMLè§£æ â†’ æ‰å¹³åŒ– | PostgreSQL JSONB + Milvus | æ··åˆæ£€ç´¢ | APIæ•°æ®ã€é…ç½®æ–‡ä»¶ |

### 1.3 AI Agentå‘å±•è„‰ç»œä¸­çš„æ•°æ®æ¼”è¿›

```mermaid
graph LR
    subgraph "Phase 1: åŸºç¡€Agent"
        P1["é™æ€æ•°æ®<br/>Static Data"]
        P1_1["é¢„å®šä¹‰è§„åˆ™"]
        P1_2["å›ºå®šçŸ¥è¯†åº“"]
    end
    
    subgraph "Phase 2: RAGå¢å¼ºAgent"
        P2["åŠ¨æ€æ£€ç´¢æ•°æ®<br/>Dynamic Retrieval"]
        P2_1["å‘é‡æ£€ç´¢"]
        P2_2["æ··åˆæ£€ç´¢"]
        P2_3["å®æ—¶æ›´æ–°"]
    end
    
    subgraph "Phase 3: è‡ªå­¦ä¹ Agent"
        P3["åé¦ˆé©±åŠ¨æ•°æ®<br/>Feedback-driven"]
        P3_1["ç”¨æˆ·åé¦ˆ"]
        P3_2["æ‰§è¡Œè¿½è¸ª"]
        P3_3["è‡ªåŠ¨ä¼˜åŒ–"]
    end
    
    subgraph "Phase 4: è‡ªä¸»æ¼”è¿›Agent"
        P4["è‡ªä¸»æ²»ç†æ•°æ®<br/>Autonomous"]
        P4_1["æ•°æ®è¡€ç¼˜"]
        P4_2["è´¨é‡ç›‘æ§"]
        P4_3["è‡ªåŠ¨ä¿®å¤"]
    end
    
    P1 --> P2 --> P3 --> P4
```

OpenEAAPå½“å‰å¤„äº**Phase 2å‘Phase 3è¿‡æ¸¡**é˜¶æ®µï¼Œå·²å®ç°RAGå¼•æ“å’Œåé¦ˆæ”¶é›†æœºåˆ¶ [3](#0-2) ã€‚

## äºŒã€AI Data å‚è€ƒæ¶æ„ï¼ˆRA - Reference Architectureï¼‰

### 2.1 åˆ†å±‚æ¶æ„è®¾è®¡

OpenEAAPé‡‡ç”¨**ä¸ƒå±‚DDDæ¶æ„**ï¼ŒAI Dataèƒ½åŠ›è´¯ç©¿æ‰€æœ‰å±‚æ¬¡ [4](#0-3) ï¼š

```mermaid
graph TB
    subgraph "Layer 7: æ¥å£å±‚ Interface Layer"
        L7_1["HTTP API<br/>æ–‡æ¡£ä¸Šä¼ /æŸ¥è¯¢"]
        L7_2["gRPC API<br/>æµå¼æ£€ç´¢"]
        L7_3["CLI<br/>æ•°æ®ç®¡ç†å‘½ä»¤"]
    end
    
    subgraph "Layer 6: åº”ç”¨å±‚ Application Layer"
        L6_1["DataService<br/>æ•°æ®æœåŠ¡ç¼–æ’"]
        L6_2["AgentService<br/>Agentæ‰§è¡ŒæœåŠ¡"]
    end
    
    subgraph "Layer 5: å¹³å°å±‚ Platform Layer"
        L5_1["RAG Engine<br/>æ£€ç´¢å¢å¼ºç”Ÿæˆ"]
        L5_2["Document Processor<br/>æ–‡æ¡£å¤„ç†æµæ°´çº¿"]
        L5_3["Feedback Collector<br/>åé¦ˆæ”¶é›†å™¨"]
        L5_4["Online Learning Engine<br/>åœ¨çº¿å­¦ä¹ å¼•æ“"]
    end
    
    subgraph "Layer 4: é¢†åŸŸå±‚ Domain Layer"
        L4_1["Document Entity<br/>æ–‡æ¡£å®ä½“"]
        L4_2["Chunk Entity<br/>åˆ†å—å®ä½“"]
        L4_3["Knowledge Entity<br/>çŸ¥è¯†å®ä½“"]
    end
    
    subgraph "Layer 3: åŸºç¡€è®¾æ–½å±‚ Infrastructure Layer"
        L3_1["KnowledgeRepository<br/>çŸ¥è¯†åº“ä»“å‚¨"]
        L3_2["VectorDB Client<br/>å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯"]
        L3_3["Cache Client<br/>ç¼“å­˜å®¢æˆ·ç«¯"]
    end
    
    subgraph "Layer 2: æ²»ç†å±‚ Governance Layer"
        L2_1["PII Detector<br/>éšç§æ£€æµ‹"]
        L2_2["Data Lineage Tracker<br/>æ•°æ®è¡€ç¼˜è¿½è¸ª"]
        L2_3["Audit Logger<br/>å®¡è®¡æ—¥å¿—"]
    end
    
    subgraph "Layer 1: å¯è§‚æµ‹æ€§å±‚ Observability Layer"
        L1_1["Distributed Tracing<br/>åˆ†å¸ƒå¼è¿½è¸ª"]
        L1_2["Metrics Collection<br/>æŒ‡æ ‡æ”¶é›†"]
    end
    
    L7_1 & L7_2 & L7_3 --> L6_1 & L6_2
    L6_1 & L6_2 --> L5_1 & L5_2 & L5_3 & L5_4
    L5_1 & L5_2 --> L4_1 & L4_2 & L4_3
    L4_1 & L4_2 & L4_3 --> L3_1 & L3_2 & L3_3
    
    L2_1 & L2_2 & L2_3 -.æ¨ªåˆ‡å…³æ³¨ç‚¹.-> L5_1 & L5_2
    L1_1 & L1_2 -.ç›‘æ§.-> L5_1 & L5_2
```

### 2.2 æ•°æ®å¤„ç†æµæ°´çº¿æ¶æ„

OpenEAAPå®ç°äº†å®Œæ•´çš„æ•°æ®å¤„ç†æµæ°´çº¿ï¼Œæ”¯æŒä»æ‘„å–åˆ°åº”ç”¨çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç† [5](#0-4) ï¼š

```mermaid
graph LR
    subgraph "æ•°æ®æ‘„å– Ingestion"
        I1["æ–‡ä»¶ä¸Šä¼ <br/>File Upload"]
        I2["APIæ¥å…¥<br/>API Ingestion"]
        I3["æ•°æ®åŒæ­¥<br/>Data Sync"]
    end
    
    subgraph "æ•°æ®å¤„ç† Processing"
        P1["è§£æå™¨<br/>Parser<br/>å¤šæ ¼å¼æ”¯æŒ"]
        P2["åˆ†å—å™¨<br/>Chunker<br/>4ç§ç­–ç•¥"]
        P3["å‘é‡åŒ–<br/>Embedder<br/>è¯­ä¹‰è¡¨ç¤º"]
        P4["PIIæ£€æµ‹<br/>PII Detector<br/>è‡ªåŠ¨è„±æ•"]
    end
    
    subgraph "æ•°æ®å­˜å‚¨ Storage"
        S1["æ–‡æ¡£åº“<br/>PostgreSQL"]
        S2["å‘é‡åº“<br/>Milvus"]
        S3["å¯¹è±¡å­˜å‚¨<br/>MinIO"]
    end
    
    subgraph "æ•°æ®æ£€ç´¢ Retrieval"
        R1["RAGå¼•æ“<br/>æ··åˆæ£€ç´¢"]
        R2["é‡æ’åº<br/>Reranking"]
        R3["ä¸Šä¸‹æ–‡æ„å»º<br/>Context Building"]
    end
    
    subgraph "æ•°æ®åº”ç”¨ Application"
        A1["Agentè°ƒç”¨"]
        A2["æ¨¡å‹æ¨ç†"]
        A3["ç»“æœç”Ÿæˆ"]
    end
    
    I1 & I2 & I3 --> P1 --> P2 --> P3
    P2 --> P4
    P3 --> S2
    P4 --> S1
    I1 --> S3
    
    S1 & S2 --> R1 --> R2 --> R3 --> A1 --> A2 --> A3
```

**åˆ†å—ç­–ç•¥è¯¦è§£** [6](#0-5) ï¼š

| ç­–ç•¥ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|
| **å›ºå®šé•¿åº¦** | æŒ‰å›ºå®šTokenæ•°åˆ†å— | é€šç”¨æ–‡æ¡£ã€APIæ–‡æ¡£ |
| **è¯­ä¹‰è¾¹ç•Œ** | æŒ‰æ®µè½ã€ç« èŠ‚åˆ†å— | ç»“æ„åŒ–æ–‡æ¡£ã€æŠ€æœ¯è§„èŒƒ |
| **æ»‘åŠ¨çª—å£** | é‡å åˆ†å—ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤± | é•¿ç¯‡æ–‡æ¡£ã€æ³•å¾‹åˆåŒ |
| **å±‚æ¬¡åˆ†å—** | å¤šç²’åº¦åˆ†å—ï¼ˆå¥å­ã€æ®µè½ã€ç« èŠ‚ï¼‰ | å¤æ‚æ–‡æ¡£ã€å­¦æœ¯è®ºæ–‡ |

### 2.3 æ•°æ®è¡€ç¼˜ä¸æ²»ç†æ¶æ„

OpenEAAPå®ç°äº†å®Œæ•´çš„æ•°æ®è¡€ç¼˜è¿½è¸ªæœºåˆ¶ï¼Œç¡®ä¿æ•°æ®çš„å¯è¿½æº¯æ€§å’Œåˆè§„æ€§ [7](#0-6) ï¼š

```mermaid
graph LR
    subgraph "æ•°æ®æº Sources"
        S1["åŸå§‹æ–‡æ¡£<br/>Raw Documents"]
        S2["APIæ•°æ®<br/>API Data"]
        S3["ç”¨æˆ·åé¦ˆ<br/>User Feedback"]
    end
    
    subgraph "è½¬æ¢å±‚ Transformation"
        T1["è§£æ<br/>Parsing"]
        T2["åˆ†å—<br/>Chunking"]
        T3["å‘é‡åŒ–<br/>Vectorization"]
        T4["PIIè„±æ•<br/>PII Masking"]
    end
    
    subgraph "å­˜å‚¨å±‚ Storage"
        ST1["æ–‡æ¡£åº“<br/>Doc Store"]
        ST2["å‘é‡åº“<br/>Vector Store"]
        ST3["çŸ¥è¯†å›¾è°±<br/>Knowledge Graph"]
    end
    
    subgraph "ä½¿ç”¨å±‚ Usage"
        U1["RAGæ£€ç´¢<br/>RAG Retrieval"]
        U2["æ¨¡å‹å¾®è°ƒ<br/>Model Fine-tuning"]
        U3["Agentè°ƒç”¨<br/>Agent Execution"]
    end
    
    S1 -.è¡€ç¼˜lineage.-> T1
    T1 -.è¡€ç¼˜.-> T2
    T2 -.è¡€ç¼˜.-> T3
    T2 -.è¡€ç¼˜.-> T4
    T3 -.è¡€ç¼˜.-> ST2
    T4 -.è¡€ç¼˜.-> ST1
    ST2 -.è¡€ç¼˜.-> U1
    S3 -.è¡€ç¼˜.-> U2
    U1 -.è¡€ç¼˜.-> U3
```

### 2.4 æ•°æ®åé¦ˆé—­ç¯æ¶æ„

OpenEAAPæ„å»ºäº†ä»ä¸šåŠ¡åé¦ˆåˆ°æ•°æ®ä¼˜åŒ–çš„å…¨è‡ªåŠ¨åŒ–é—­ç¯ [8](#0-7) ï¼š

```mermaid
graph TB
    subgraph "åé¦ˆæº Feedback Sources"
        FS1["ç”¨æˆ·ä¿®æ­£<br/>User Correction"]
        FS2["è¯„åˆ†åé¦ˆ<br/>Rating Feedback"]
        FS3["è‡ªåŠ¨è¯„ä¼°<br/>Auto Evaluation"]
    end
    
    subgraph "æ•°æ®æ”¶é›† Data Collection"
        DC1["åé¦ˆæ”¶é›†å™¨<br/>Feedback Collector"]
        DC2["è´¨é‡è¿‡æ»¤<br/>Quality Filter"]
        DC3["æ•°æ®æ¸…æ´—<br/>Data Cleaning"]
    end
    
    subgraph "æ ‡ç­¾ç”Ÿæˆ Labeling"
        LB1["è‡ªåŠ¨æ ‡æ³¨<br/>Auto Labeling"]
        LB2["äººå·¥å®¡æ ¸<br/>HITL Review"]
        LB3["æ ‡ç­¾éªŒè¯<br/>Label Validation"]
    end
    
    subgraph "æ•°æ®é›†æ„å»º Dataset Building"
        DS1["SFTæ•°æ®é›†<br/>SFT Dataset"]
        DS2["DPOæ•°æ®é›†<br/>DPO Preference Pairs"]
        DS3["è¯„ä¼°æ•°æ®é›†<br/>Evaluation Dataset"]
    end
    
    subgraph "ä¼˜åŒ–æµç¨‹ Optimization"
        OP1["Promptä¼˜åŒ–<br/>Prompt Optimization"]
        OP2["æ¨¡å‹å¾®è°ƒ<br/>Model Fine-tuning"]
        OP3["çŸ¥è¯†åº“æ›´æ–°<br/>Knowledge Base Update"]
    end
    
    FS1 & FS2 & FS3 --> DC1 --> DC2 --> DC3
    DC3 --> LB1 --> LB2 --> LB3
    LB3 --> DS1 & DS2 & DS3
    DS1 & DS2 & DS3 --> OP1 & OP2 & OP3
    OP1 & OP2 & OP3 -.æ•°æ®å›æµ.-> FS1
```

## ä¸‰ã€AI Data å‚è€ƒå®ç°ï¼ˆRI - Reference Implementationï¼‰

### 3.1 RAGå¼•æ“æ ¸å¿ƒå®ç°

OpenEAAPçš„RAGå¼•æ“å®ç°äº†å®Œæ•´çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæµç¨‹ [9](#0-8) ï¼š

**æ ¸å¿ƒæ¥å£å®šä¹‰ï¼š** [10](#0-9) 

**RAGè¯·æ±‚å“åº”æ¨¡å‹ï¼š** [11](#0-10) 

**å®Œæ•´RAGæŸ¥è¯¢æµç¨‹å®ç°ï¼š** [12](#0-11) 

è¯¥å®ç°åŒ…å«6ä¸ªå…³é”®é˜¶æ®µï¼š
1. **æŸ¥è¯¢ç†è§£**ï¼ˆQuery Understandingï¼‰ [13](#0-12) 
2. **æ£€ç´¢é˜¶æ®µ**ï¼ˆRetrievalï¼‰ [14](#0-13) 
3. **é‡æ’åºé˜¶æ®µ**ï¼ˆRerankingï¼‰ [15](#0-14) 
4. **ä¸Šä¸‹æ–‡æ„å»º**ï¼ˆContext Buildingï¼‰ [16](#0-15) 
5. **ç”Ÿæˆé˜¶æ®µ**ï¼ˆGenerationï¼‰ [17](#0-16) 
6. **éªŒè¯é˜¶æ®µ**ï¼ˆVerificationï¼‰ [18](#0-17) 

### 3.2 æ£€ç´¢ç­–ç•¥å®ç°

OpenEAAPæ”¯æŒå››ç§æ£€ç´¢æ¨¡å¼ [19](#0-18) ï¼š

- **å‘é‡æ£€ç´¢ï¼ˆVector Searchï¼‰**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ£€ç´¢
- **å…³é”®è¯æ£€ç´¢ï¼ˆKeyword Searchï¼‰**ï¼šåŸºäºç²¾ç¡®åŒ¹é…çš„æ£€ç´¢  
- **æ··åˆæ£€ç´¢ï¼ˆHybrid Retrievalï¼‰**ï¼šç»“åˆå‘é‡å’Œå…³é”®è¯çš„æ£€ç´¢
- **çŸ¥è¯†å›¾è°±æ£€ç´¢ï¼ˆGraph Searchï¼‰**ï¼šåŸºäºå…³ç³»çš„æ£€ç´¢

æ£€ç´¢å®ç°åŒ…å«æ™ºèƒ½ä¸Šä¸‹æ–‡é•¿åº¦æ§åˆ¶ [20](#0-19) ã€‚

### 3.3 æµå¼RAGå®ç°

OpenEAAPæä¾›æµå¼RAGæŸ¥è¯¢èƒ½åŠ›ï¼Œæ”¯æŒå®æ—¶å“åº” [21](#0-20) ï¼š

**æµå¼å“åº”æ¨¡å‹ï¼š** [22](#0-21) 

### 3.4 ç­”æ¡ˆéªŒè¯æœºåˆ¶

OpenEAAPå®ç°äº†å¤šç»´åº¦çš„ç­”æ¡ˆéªŒè¯æœºåˆ¶ [23](#0-22) ï¼š

**éªŒè¯å®ç°ï¼š** [24](#0-23) 

éªŒè¯ç»´åº¦åŒ…æ‹¬ï¼š
- **å¹»è§‰æ£€æµ‹ï¼ˆHallucination Detectionï¼‰**ï¼šæ£€æŸ¥ç­”æ¡ˆæ˜¯å¦è„±ç¦»æ£€ç´¢å†…å®¹
- **å¼•ç”¨æœ‰æ•ˆæ€§ï¼ˆCitation Validityï¼‰**ï¼šéªŒè¯ç­”æ¡ˆæ˜¯å¦å¼•ç”¨äº†æ£€ç´¢åˆ°çš„å†…å®¹
- **äº‹å®æ ¸æŸ¥ï¼ˆFact Checkï¼‰**ï¼šæ£€æŸ¥ç­”æ¡ˆçš„åˆç†æ€§

### 3.5 ä¸‰çº§ç¼“å­˜æ¶æ„å®ç°

OpenEAAPå®ç°äº†ä¸šç•Œé¢†å…ˆçš„ä¸‰çº§ç¼“å­˜æ¶æ„ï¼Œæ˜¾è‘—é™ä½æ¨ç†æˆæœ¬å’Œå»¶è¿Ÿ [25](#0-24) ï¼š

**ç¼“å­˜å±‚çº§ç­–ç•¥ï¼š**

| å±‚çº§ | å­˜å‚¨ä»‹è´¨ | åŒ¹é…ç­–ç•¥ | å‘½ä¸­ç‡ | å»¶è¿Ÿ | å®ç°è·¯å¾„ |
|-----|---------|---------|--------|------|---------|
| **L1æœ¬åœ°ç¼“å­˜** | è¿›ç¨‹å†…å­˜ | ç²¾ç¡®HashåŒ¹é… | 20-30% | <1ms | Go map + LRUæ·˜æ±° |
| **L2è¯­ä¹‰ç¼“å­˜** | Redisé›†ç¾¤ | è¯­ä¹‰Hash | 30-40% | <10ms | Rediså®¢æˆ·ç«¯ |
| **L3å‘é‡ç¼“å­˜** | Milvus | ä½™å¼¦ç›¸ä¼¼åº¦ | 10-20% | <50ms | Milvuså®¢æˆ·ç«¯ |

**æ€§èƒ½ä¼˜åŠ¿ï¼š**
- ç´¯è®¡ç¼“å­˜å‘½ä¸­ç‡ï¼š**60-90%**
- P95å»¶è¿Ÿé™ä½ï¼š**70%**
- æ¨ç†æˆæœ¬é™ä½ï¼š**60%** [26](#0-25) 

### 3.6 æ•°æ®å­˜å‚¨é€‰å‹å®ç°

OpenEAAPé’ˆå¯¹ä¸åŒæ•°æ®ç±»å‹é€‰æ‹©æœ€ä¼˜å­˜å‚¨æ–¹æ¡ˆ [27](#0-26) ï¼š

| æ•°æ®ç±»å‹ | å­˜å‚¨æŠ€æœ¯ | ç”¨é€” |
|---------|---------|------|
| **å…³ç³»æ•°æ®** | PostgreSQL | ç”¨æˆ·ã€Agentã€æ‰§è¡Œè®°å½•ç­‰ç»“æ„åŒ–æ•°æ® |
| **å‘é‡æ•°æ®** | Milvus/Qdrant | æ–‡æ¡£å‘é‡ã€Embedding |
| **å›¾æ•°æ®** | Neo4j | çŸ¥è¯†å›¾è°±ã€æ•°æ®è¡€ç¼˜ |
| **æ—¶åºæ•°æ®** | InfluxDB | Traceã€æŒ‡æ ‡ã€æ—¥å¿— |
| **ç¼“å­˜** | Redis | L2è¯­ä¹‰ç¼“å­˜ã€ä¼šè¯çŠ¶æ€ |
| **å¯¹è±¡å­˜å‚¨** | MinIO/S3 | åŸå§‹æ–‡æ¡£ã€æ¨¡å‹æ–‡ä»¶ |

## å››ã€é’ˆå¯¹å…·ä½“åœºæ™¯çš„AI Dataåº”ç”¨

### 4.1 å®‰å…¨æ—¥å¿—æ•°æ®åœºæ™¯ï¼ˆSOC Copilotï¼‰

OpenEAAPæä¾›äº†å®Œæ•´çš„å®‰å…¨è¿è¥æ™ºèƒ½åŠ©æ‰‹å®ç° [28](#0-27) ï¼š

**æ•°æ®æµæ¶æ„ï¼š** [29](#0-28) 

**æ ¸å¿ƒèƒ½åŠ›ï¼š**
- å¨èƒæƒ…æŠ¥æŸ¥è¯¢ï¼šé›†æˆSIEMã€TIå¹³å°API
- æ—¥å¿—å…³è”åˆ†æï¼šRAGæ£€ç´¢ + LLMæ¨ç†
- å†å²æ¡ˆä¾‹æ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + çŸ¥è¯†å›¾è°±
- å“åº”å»ºè®®ç”Ÿæˆï¼šåŸºäºæ¡ˆä¾‹åº“çš„Promptå·¥ç¨‹
- äººåœ¨å›è·¯ï¼ˆHITLï¼‰ï¼šå…³é”®æ“ä½œéœ€äººå·¥å®¡æ ¸

**æ•ˆæœæŒ‡æ ‡ï¼š**
- åˆ†æè€—æ—¶ï¼šä»30åˆ†é’Ÿé™è‡³<5åˆ†é’Ÿ
- è¯¯æŠ¥ç‡ï¼šä»40%é™è‡³<15%
- å“åº”é€Ÿåº¦ï¼šä»2å°æ—¶é™è‡³<30åˆ†é’Ÿ [30](#0-29) 

### 4.2 ä¼ä¸šæ–‡æ¡£æ•°æ®åœºæ™¯

OpenEAAPå®ç°äº†æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿ [31](#0-30) ï¼š

**æ–‡æ¡£å¤„ç†æµç¨‹ï¼š** [32](#0-31) 

å¤„ç†æµç¨‹åŒ…æ‹¬ï¼š
1. æ–‡æ¡£è§£æï¼ˆæ”¯æŒPDFã€Wordã€Markdownç­‰ï¼‰
2. PIIæ£€æµ‹ä¸è‡ªåŠ¨è„±æ•
3. æ™ºèƒ½åˆ†å—ï¼ˆ4ç§ç­–ç•¥ï¼‰
4. å‘é‡åŒ–ï¼ˆç”ŸæˆEmbeddingï¼‰

## äº”ã€AI Dataæ¼”è¿›è·¯çº¿å›¾

åŸºäºOpenEAAPçš„è·¯çº¿å›¾ [33](#0-32) ï¼š

### Phase 1: åŸºç¡€å¹³å°ï¼ˆ2026 Q1-Q2ï¼‰âœ… å·²å®Œæˆ
- æ ¸å¿ƒæ¡†æ¶æ­å»ºï¼ˆDDDæ¶æ„ï¼‰
- ç¼–æ’å™¨ä¸è¿è¡Œæ—¶
- æ¨ç†ç½‘å…³ï¼ˆvLLMé›†æˆï¼‰
- ä¸‰çº§ç¼“å­˜æ¶æ„

### Phase 2: æ•°æ®æ™ºèƒ½ï¼ˆ2026 Q2-Q3ï¼‰ğŸš§ è¿›è¡Œä¸­
- RAGå¼•æ“ï¼ˆæ··åˆæ£€ç´¢ã€é‡æ’åºï¼‰
- å‘é‡æ•°æ®åº“é›†æˆï¼ˆMilvusï¼‰
- çŸ¥è¯†å›¾è°±æ„å»º
- æ–‡æ¡£å¤„ç†æµæ°´çº¿

### Phase 3: æŒç»­ä¼˜åŒ–ï¼ˆ2026 Q3-Q4ï¼‰ğŸ“… è§„åˆ’ä¸­
- åœ¨çº¿å­¦ä¹ å¼•æ“
- RLHF/DPOè®­ç»ƒæµç¨‹
- Promptè‡ªåŠ¨ä¼˜åŒ–
- A/Bæµ‹è¯•æ¡†æ¶

### Phase 4: æ²»ç†å¢å¼ºï¼ˆ2026 Q4-2027 Q1ï¼‰ğŸ“… è§„åˆ’ä¸­
- ç­–ç•¥å¼•æ“ï¼ˆABAC/RBACï¼‰
- éšç§è®¡ç®—ç½‘å…³ï¼ˆPIIæ£€æµ‹ä¸è„±æ•ï¼‰
- å®¡è®¡ä¸åˆè§„ï¼ˆSOC2ã€GDPRï¼‰

## Notes

OpenEAAPé¡¹ç›®ä¸ºAI Dataæä¾›äº†å®Œæ•´çš„**å‚è€ƒæ¨¡å‹ã€å‚è€ƒæ¶æ„å’Œå‚è€ƒå®ç°**ï¼Œç‰¹åˆ«å€¼å¾—å…³æ³¨çš„æ˜¯ï¼š

1. **DIKFå¹³å°**æ˜¯AI Dataèƒ½åŠ›çš„æ ¸å¿ƒè½½ä½“ï¼Œå®ç°äº†ä»æ•°æ®æ‘„å–åˆ°åº”ç”¨çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†

2. **ä¸‰çº§ç¼“å­˜æ¶æ„**æ˜¯æ€§èƒ½ä¼˜åŒ–çš„å…³é”®åˆ›æ–°ï¼Œé€šè¿‡L1æœ¬åœ°ç¼“å­˜ï¼ˆ<1msï¼‰ã€L2è¯­ä¹‰ç¼“å­˜ï¼ˆ<10msï¼‰ã€L3å‘é‡ç¼“å­˜ï¼ˆ<50msï¼‰å®ç°60-90%çš„å‘½ä¸­ç‡

3. **æ•°æ®åé¦ˆé—­ç¯**å»ºç«‹äº†ä»ç”¨æˆ·åé¦ˆåˆ°æ¨¡å‹ä¼˜åŒ–çš„è‡ªåŠ¨åŒ–æµç¨‹ï¼Œæ”¯æŒRLHF/DPOè®­ç»ƒå’ŒPromptè‡ªåŠ¨ä¼˜åŒ–

4. **å¤šç­–ç•¥åˆ†å—æœºåˆ¶**é’ˆå¯¹ä¸åŒæ–‡æ¡£ç±»å‹æä¾›4ç§åˆ†å—ç­–ç•¥ï¼Œç¡®ä¿è¯­ä¹‰å®Œæ•´æ€§

5. **æ•°æ®è¡€ç¼˜è¿½è¸ª**å®ç°äº†ä»æ•°æ®æºåˆ°æœ€ç»ˆåº”ç”¨çš„å…¨é“¾è·¯å¯è¿½æº¯ï¼Œæ»¡è¶³åˆè§„è¦æ±‚

6. é’ˆå¯¹**å®‰å…¨æ—¥å¿—ã€ä¼ä¸šæ–‡æ¡£ã€ä¸šåŠ¡åˆ†æ**ç­‰ä¸åŒæ•°æ®ç±»å‹ï¼ŒOpenEAAPæä¾›äº†å·®å¼‚åŒ–çš„å­˜å‚¨å’Œæ£€ç´¢æ–¹æ¡ˆ

è¯¥æ¶æ„å·²åœ¨å®é™…ä»£ç ä¸­å¾—åˆ°éªŒè¯ï¼Œå¯ä½œä¸ºæ„å»ºä¼ä¸šçº§AI Dataå¹³å°çš„é‡è¦å‚è€ƒã€‚

### Citations

**File:** docs/architecture.md (L20-20)
```markdown
| **DIKF**     | Data Intelligence & Knowledge Fabric       | æ•°æ®æ™ºèƒ½ä¸çŸ¥è¯†ç¼–ç»‡å¹³å°         |
```

**File:** docs/architecture.md (L749-791)
```markdown
### 4.2 æ•°æ®æ™ºèƒ½ä¸çŸ¥è¯†ç¼–ç»‡å¹³å°ï¼ˆDIKFï¼‰

#### 4.2.1 ç»„ä»¶æ¶æ„

```mermaid
graph TB
    subgraph Ingestion[æ•°æ®æ¥å…¥å±‚]
        FILE[æ–‡ä»¶ä¸Šä¼ ]
        API[API æ¥å…¥]
        SYNC[æ•°æ®åŒæ­¥]
    end
    
    subgraph Processing[æ•°æ®å¤„ç†å±‚]
        PARSE[è§£æå™¨]
        CHUNK[åˆ†å—å™¨]
        EMBED[å‘é‡åŒ–]
        PII[PII æ£€æµ‹]
    end
    
    subgraph Storage[å­˜å‚¨å±‚]
        VDB[å‘é‡æ•°æ®åº“]
        KG[çŸ¥è¯†å›¾è°±]
        DOC[æ–‡æ¡£å­˜å‚¨]
    end
    
    subgraph Retrieval[æ£€ç´¢å±‚]
        RAG[RAG å¼•æ“]
        HYBRID[æ··åˆæ£€ç´¢]
        RERANK[é‡æ’åº]
    end
    
    subgraph Governance[æ²»ç†å±‚]
        LINEAGE[æ•°æ®è¡€ç¼˜]
        SENSITIVITY[æ•æ„Ÿåº¦æ ‡è®°]
        VERSION[ç‰ˆæœ¬ç®¡ç†]
    end
    
    Ingestion --> Processing
    Processing --> Storage
    Storage --> Retrieval
    Governance -.æ²»ç†.-> Processing
    Governance -.æ²»ç†.-> Storage
```
```

**File:** docs/architecture.md (L873-914)
```markdown

OpenEAAP æ„å»ºäº†ä»ä¸šåŠ¡åé¦ˆåˆ°æ•°æ®ä¼˜åŒ–çš„å…¨è‡ªåŠ¨åŒ–é—­ç¯ï¼š

```mermaid
graph TB
    subgraph Source[åé¦ˆæº]
        S1[ç”¨æˆ·ä¿®æ­£<br/>User Correction]
        S2[ç‚¹èµ/ç‚¹è¸©<br/>Thumbs Up/Down]
        S3[è‡ªåŠ¨è¯„ä¼°<br/>Auto Evaluation]
    end
    
    subgraph Collection[æ•°æ®æ”¶é›†]
        C1[åé¦ˆæ”¶é›†å™¨<br/>Feedback Collector]
        C2[è´¨é‡è¿‡æ»¤<br/>Quality Filter]
        C3[æ•°æ®æ¸…æ´—<br/>Data Cleaning]
    end
    
    subgraph Labeling[æ ‡ç­¾ç”Ÿæˆ]
        L1[è‡ªåŠ¨æ ‡æ³¨<br/>Auto Labeling]
        L2[äººå·¥å®¡æ ¸<br/>HITL Review]
        L3[æ ‡ç­¾éªŒè¯<br/>Label Validation]
    end
    
    subgraph Dataset[æ•°æ®é›†æ„å»º]
        D1[SFT æ•°æ®é›†<br/>SFT Dataset]
        D2[DPO æ•°æ®é›†<br/>DPO Dataset]
        D3[è¯„ä¼°æ•°æ®é›†<br/>Eval Dataset]
    end
    
    subgraph Optimization[ä¼˜åŒ–æµç¨‹]
        O1[Prompt ä¼˜åŒ–<br/>Prompt Optimization]
        O2[æ¨¡å‹å¾®è°ƒ<br/>Model Fine-tuning]
        O3[çŸ¥è¯†åº“æ›´æ–°<br/>KB Update]
    end
    
    Source --> Collection
    Collection --> Labeling
    Labeling --> Dataset
    Dataset --> Optimization
    
    Optimization -.å›æµ.-> Source
```
```

**File:** docs/architecture.md (L1112-1164)
```markdown
#### 4.3.3 ä¸‰çº§ç¼“å­˜æ¶æ„

ä¸ºé™ä½é‡å¤æŸ¥è¯¢æˆæœ¬ï¼ŒOpenEAAP è®¾è®¡äº†ä¸‰çº§ç¼“å­˜æ¶æ„ï¼š

```mermaid
graph TB
    REQ[è¯·æ±‚] --> L1{L1 æœ¬åœ° Hash}
    L1 -->|å‘½ä¸­| HIT1[è¿”å›ç»“æœ]
    L1 -->|æœªå‘½ä¸­| L2{L2 Redis è¯­ä¹‰}
    L2 -->|å‘½ä¸­| HIT2[è¿”å›ç»“æœ]
    L2 -->|æœªå‘½ä¸­| L3{L3 å‘é‡ç›¸ä¼¼åº¦}
    L3 -->|ç›¸ä¼¼åº¦>0.95| HIT3[è¿”å›ç›¸ä¼¼ç»“æœ]
    L3 -->|ç›¸ä¼¼åº¦<0.95| LLM[è°ƒç”¨ LLM]
    LLM --> CACHE[å†™å…¥ç¼“å­˜]
    CACHE --> RES[è¿”å›ç»“æœ]
```

**ç¼“å­˜ç­–ç•¥**:

| å±‚çº§     | å­˜å‚¨    | åŒ¹é…æ–¹å¼    | å‘½ä¸­ç‡    | å»¶è¿Ÿ     |
| ------ | ----- | ------- | ------ | ------ |
| **L1** | è¿›ç¨‹å†…å­˜  | ç²¾ç¡® Hash | 20-30% | < 1ms  |
| **L2** | Redis | è¯­ä¹‰ Hash | 30-40% | < 10ms |
| **L3** | å‘é‡æ•°æ®åº“ | ä½™å¼¦ç›¸ä¼¼åº¦   | 10-20% | < 50ms |

**ç¼“å­˜æ¥å£**:

```go
// ç¼“å­˜ç®¡ç†å™¨æ¥å£
type CacheManager interface {
    // æŸ¥è¯¢ç¼“å­˜
    Get(ctx context.Context, key string) (*CachedResult, error)
    
    // è¯­ä¹‰æŸ¥è¯¢ï¼ˆL2/L3ï¼‰
    GetSemantic(ctx context.Context, query string, threshold float64) (*CachedResult, error)
    
    // å†™å…¥ç¼“å­˜
    Set(ctx context.Context, key string, value *CachedResult, ttl time.Duration) error
    
    // å¤±æ•ˆç¼“å­˜
    Invalidate(ctx context.Context, key string) error
}

// ç¼“å­˜ç»“æœ
type CachedResult struct {
    Key        string    // ç¼“å­˜é”®
    Value      string    // ç¼“å­˜å€¼
    Embedding  []float64 // å‘é‡ï¼ˆç”¨äº L3ï¼‰
    Similarity float64   // ç›¸ä¼¼åº¦ï¼ˆL3 å‘½ä¸­æ—¶ï¼‰
    TTL        time.Duration // è¿‡æœŸæ—¶é—´
    CreatedAt  time.Time // åˆ›å»ºæ—¶é—´
}
```
```

**File:** docs/architecture.md (L1454-1556)
```markdown
## 5. å…³é”®ä¸šåŠ¡åœºæ™¯è®¾è®¡

### 5.1 å®‰å…¨è¿è¥æ™ºèƒ½åŠ©æ‰‹ï¼ˆSOC Copilotï¼‰

#### 5.1.1 åœºæ™¯æè¿°

å®‰å…¨è¿è¥æ™ºèƒ½åŠ©æ‰‹é¢å‘ SOCï¼ˆSecurity Operations Centerï¼‰å›¢é˜Ÿï¼Œæä¾›æ™ºèƒ½åŒ–çš„å¨èƒæ£€æµ‹ã€äº‹ä»¶åˆ†æã€å“åº”å»ºè®®ç­‰èƒ½åŠ›ã€‚

#### 5.1.2 ä¸šåŠ¡æµç¨‹

```mermaid
sequenceDiagram
    participant Analyst as å®‰å…¨åˆ†æå¸ˆ
    participant Copilot as SOC Copilot
    participant SIEM as SIEM ç³»ç»Ÿ
    participant TI as å¨èƒæƒ…æŠ¥åº“
    participant RAG as RAG å¼•æ“
    participant LLM as æ¨ç†æœåŠ¡
    participant Action as å“åº”ç³»ç»Ÿ
    
    Analyst->>Copilot: "åˆ†æè¿™ä¸ªå¯ç–‘ IP: 192.168.1.100"
    Copilot->>SIEM: æŸ¥è¯¢å…³è”æ—¥å¿—
    SIEM-->>Copilot: è¿”å›æ—¥å¿—æ•°æ®
    
    Copilot->>TI: æŸ¥è¯¢å¨èƒæƒ…æŠ¥
    TI-->>Copilot: è¿”å› IP ä¿¡èª‰æ•°æ®
    
    Copilot->>RAG: æ£€ç´¢å†å²å¤„ç½®æ¡ˆä¾‹
    RAG-->>Copilot: è¿”å›ç›¸ä¼¼æ¡ˆä¾‹
    
    Copilot->>LLM: ç»¼åˆåˆ†æï¼ˆæ—¥å¿—+æƒ…æŠ¥+æ¡ˆä¾‹ï¼‰
    LLM-->>Copilot: ç”Ÿæˆåˆ†ææŠ¥å‘Š
    
    Copilot->>Analyst: å±•ç¤ºåˆ†æç»“æœä¸å»ºè®®
    Analyst->>Copilot: "æ‰§è¡Œå°ç¦æ“ä½œ"
    
    Copilot->>Action: æäº¤å°ç¦è¯·æ±‚ï¼ˆHITLå®¡æ ¸ï¼‰
    Action-->>Copilot: è¿”å›æ‰§è¡Œç»“æœ
    
    Copilot->>Analyst: "å·²å®Œæˆå°ç¦ï¼Œè¯·ç¡®è®¤"
```

#### 5.1.3 æ ¸å¿ƒèƒ½åŠ›

| èƒ½åŠ›             | è¯´æ˜         | æŠ€æœ¯å®ç°              |
| -------------- | ---------- | ----------------- |
| **å¨èƒæƒ…æŠ¥æŸ¥è¯¢**     | è‡ªåŠ¨æŸ¥è¯¢å¤šæºå¨èƒæƒ…æŠ¥ | é›†æˆ SIEMã€TI å¹³å° API |
| **æ—¥å¿—å…³è”åˆ†æ**     | å¤šç»´åº¦æ—¥å¿—å…³è”    | RAG æ£€ç´¢ + LLM æ¨ç†   |
| **å†å²æ¡ˆä¾‹æ£€ç´¢**     | æ£€ç´¢ç›¸ä¼¼å†å²æ¡ˆä¾‹   | å‘é‡æ£€ç´¢ + çŸ¥è¯†å›¾è°±       |
| **å“åº”å»ºè®®ç”Ÿæˆ**     | ç”Ÿæˆå¤„ç½®å»ºè®®     | åŸºäºæ¡ˆä¾‹åº“çš„ Prompt å·¥ç¨‹  |
| **äººåœ¨å›è·¯ï¼ˆHITLï¼‰** | å…³é”®æ“ä½œéœ€äººå·¥å®¡æ ¸  | Workflow å®¡æ‰¹æœºåˆ¶     |
| **æŒç»­å­¦ä¹ **       | ä»å¤„ç½®åé¦ˆä¸­å­¦ä¹    | åœ¨çº¿å­¦ä¹ å¼•æ“            |

#### 5.1.4 æŠ€æœ¯æ¶æ„

```mermaid
graph TB
    subgraph Input[è¾“å…¥å±‚]
        I1[åˆ†æå¸ˆæŸ¥è¯¢]
        I2[å‘Šè­¦è§¦å‘]
    end
    
    subgraph Orchestrator[ç¼–æ’å±‚]
        O1[æ„å›¾è¯†åˆ«]
        O2[ä»»åŠ¡åˆ†è§£]
        O3[å·¥å…·è°ƒç”¨]
    end
    
    subgraph Tools[å·¥å…·å±‚]
        T1[SIEM API]
        T2[å¨èƒæƒ…æŠ¥ API]
        T3[RAG æ£€ç´¢]
        T4[çŸ¥è¯†å›¾è°±æŸ¥è¯¢]
    end
    
    subgraph Analysis[åˆ†æå±‚]
        A1[æ—¥å¿—è§£æ]
        A2[æƒ…æŠ¥å…³è”]
        A3[é£é™©è¯„ä¼°]
        A4[å»ºè®®ç”Ÿæˆ]
    end
    
    subgraph Output[è¾“å‡ºå±‚]
        OUT1[åˆ†ææŠ¥å‘Š]
        OUT2[å“åº”å»ºè®®]
        OUT3[æ‰§è¡Œæ“ä½œ]
    end
    
    Input --> Orchestrator
    Orchestrator --> Tools
    Tools --> Analysis
    Analysis --> Output
```

#### 5.1.5 æ•ˆæœæŒ‡æ ‡

| æŒ‡æ ‡        | åŸºçº¿    | ç›®æ ‡      | è¯´æ˜         |
| --------- | ----- | ------- | ---------- |
| **åˆ†æè€—æ—¶**  | 30 åˆ†é’Ÿ | < 5 åˆ†é’Ÿ  | ä»å‘Šè­¦åˆ°åˆæ­¥åˆ†ææŠ¥å‘Š |
| **è¯¯æŠ¥ç‡**   | 40%   | < 15%   | é™ä½è¯¯æŠ¥ï¼Œæå‡å‡†ç¡®æ€§ |
| **å“åº”é€Ÿåº¦**  | 2 å°æ—¶  | < 30 åˆ†é’Ÿ | ä»åˆ†æåˆ°æ‰§è¡Œå“åº”   |
| **çŸ¥è¯†å¤ç”¨ç‡** | -     | > 60%   | å†å²æ¡ˆä¾‹è¢«å¼•ç”¨æ¯”ä¾‹  |

```

**File:** docs/architecture.md (L1557-1642)
```markdown
### 5.2 æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿ

#### 5.2.1 åœºæ™¯æè¿°

åŸºäºä¼ä¸šå†…éƒ¨æ–‡æ¡£ï¼ˆæ”¿ç­–ã€è§„èŒƒã€æ‰‹å†Œç­‰ï¼‰æ„å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒå‘˜å·¥å¿«é€Ÿè·å–ä¿¡æ¯ã€‚

#### 5.2.2 ä¸šåŠ¡æµç¨‹

```mermaid
graph TB
    USER[ç”¨æˆ·æé—®] --> UNDERSTAND[æŸ¥è¯¢ç†è§£]
    UNDERSTAND --> ROUTE{æŸ¥è¯¢è·¯ç”±}
    
    ROUTE -->|äº‹å®æŸ¥è¯¢| VECTOR[å‘é‡æ£€ç´¢]
    ROUTE -->|æµç¨‹æŸ¥è¯¢| KG[çŸ¥è¯†å›¾è°±æ£€ç´¢]
    ROUTE -->|å¤æ‚æ¨ç†| HYBRID[æ··åˆæ£€ç´¢]
    
    VECTOR --> RERANK[é‡æ’åº]
    KG --> RERANK
    HYBRID --> RERANK
    
    RERANK --> CONTEXT[ä¸Šä¸‹æ–‡æ„å»º]
    CONTEXT --> LLM[LLM ç”Ÿæˆ]
    LLM --> VERIFY[ç­”æ¡ˆéªŒè¯]
    
    VERIFY --> CITE[å¼•ç”¨æ ‡æ³¨]
    CITE --> RESPONSE[è¿”å›ç­”æ¡ˆ]
```

#### 5.2.3 æ ¸å¿ƒæŠ€æœ¯

**æ–‡æ¡£é¢„å¤„ç†**:

```go
// æ–‡æ¡£å¤„ç†æµç¨‹
type DocumentProcessor struct {
    parser     Parser
    chunker    Chunker
    embedder   Embedder
    piiDetector PIIDetector
}

func (p *DocumentProcessor) Process(ctx context.Context, doc *Document) (*ProcessedDocument, error) {
    // 1. è§£ææ–‡æ¡£
    parsedDoc, err := p.parser.Parse(ctx, doc)
    if err != nil {
        return nil, err
    }
    
    // 2. PII æ£€æµ‹ä¸è„±æ•
    cleanedDoc, err := p.piiDetector.Mask(ctx, parsedDoc.Text, nil)
    if err != nil {
        return nil, err
    }
    
    // 3. æ™ºèƒ½åˆ†å—
    chunks, err := p.chunker.Chunk(ctx, cleanedDoc)
    if err != nil {
        return nil, err
    }
    
    // 4. å‘é‡åŒ–
    for _, chunk := range chunks {
        embedding, err := p.embedder.Embed(ctx, chunk.Text)
        if err != nil {
            return nil, err
        }
        chunk.Embedding = embedding
    }
    
    return &ProcessedDocument{
        Original: doc,
        Chunks:   chunks,
    }, nil
}
```

**æ™ºèƒ½åˆ†å—ç­–ç•¥**:

| ç­–ç•¥       | è¯´æ˜              | é€‚ç”¨åœºæ™¯  |
| -------- | --------------- | ----- |
| **å›ºå®šé•¿åº¦** | æŒ‰å›ºå®š Token æ•°åˆ†å—   | é€šç”¨æ–‡æ¡£  |
| **è¯­ä¹‰è¾¹ç•Œ** | æŒ‰æ®µè½ã€ç« èŠ‚åˆ†å—        | ç»“æ„åŒ–æ–‡æ¡£ |
| **æ»‘åŠ¨çª—å£** | é‡å åˆ†å—ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±     | é•¿ç¯‡æ–‡æ¡£  |
| **å±‚æ¬¡åˆ†å—** | å¤šç²’åº¦åˆ†å—ï¼ˆå¥å­ã€æ®µè½ã€ç« èŠ‚ï¼‰ | å¤æ‚æ–‡æ¡£  |

```

**File:** docs/architecture.md (L1985-1995)
```markdown
### 7.2 å­˜å‚¨é€‰å‹

| æ•°æ®ç±»å‹     | å­˜å‚¨æŠ€æœ¯          | è¯´æ˜                  |
| -------- | ------------- | ------------------- |
| **å…³ç³»æ•°æ®** | PostgreSQL    | ç”¨æˆ·ã€Agentã€æ‰§è¡Œè®°å½•ç­‰ç»“æ„åŒ–æ•°æ® |
| **å‘é‡æ•°æ®** | Milvus/Qdrant | æ–‡æ¡£å‘é‡ã€Embedding      |
| **å›¾æ•°æ®**  | Neo4j         | çŸ¥è¯†å›¾è°±ã€æ•°æ®è¡€ç¼˜           |
| **æ—¶åºæ•°æ®** | InfluxDB      | Traceã€æŒ‡æ ‡ã€æ—¥å¿—         |
| **ç¼“å­˜**   | Redis         | L2 è¯­ä¹‰ç¼“å­˜ã€ä¼šè¯çŠ¶æ€        |
| **å¯¹è±¡å­˜å‚¨** | MinIO/S3      | åŸå§‹æ–‡æ¡£ã€æ¨¡å‹æ–‡ä»¶           |

```

**File:** docs/architecture.md (L1996-2034)
```markdown
### 7.3 æ•°æ®è¡€ç¼˜å›¾è°±

```mermaid
graph LR
    subgraph Sources[æ•°æ®æº]
        S1[åŸå§‹æ–‡æ¡£]
        S2[API æ•°æ®]
        S3[ç”¨æˆ·åé¦ˆ]
    end
    
    subgraph Transform[è½¬æ¢å±‚]
        T1[è§£æ]
        T2[åˆ†å—]
        T3[å‘é‡åŒ–]
        T4[PII è„±æ•]
    end
    
    subgraph Storage[å­˜å‚¨å±‚]
        ST1[æ–‡æ¡£åº“]
        ST2[å‘é‡åº“]
        ST3[çŸ¥è¯†å›¾è°±]
    end
    
    subgraph Usage[ä½¿ç”¨å±‚]
        U1[RAG æ£€ç´¢]
        U2[æ¨¡å‹å¾®è°ƒ]
        U3[Agent è°ƒç”¨]
    end
    
    S1 -.lineage.-> T1
    T1 -.lineage.-> T2
    T2 -.lineage.-> T3
    T2 -.lineage.-> T4
    T3 -.lineage.-> ST2
    T4 -.lineage.-> ST1
    ST2 -.lineage.-> U1
    S3 -.lineage.-> U2
    U1 -.lineage.-> U3
```
```

**File:** README-zh.md (L85-96)
```markdown
* **ä¸‰çº§æ™ºèƒ½ç¼“å­˜**ï¼šL1 æœ¬åœ°ï¼ˆ<1msï¼‰+ L2 Redisï¼ˆ<10msï¼‰+ L3 å‘é‡ï¼ˆ<50msï¼‰ï¼Œå‘½ä¸­ç‡ 50%+
* **vLLM é›†æˆ**ï¼šPagedAttentionã€KV-Cache å…±äº«ã€æŠ•æœºè§£ç ï¼Œååé‡æå‡ 24 å€
* **æ™ºèƒ½è·¯ç”±**ï¼šæ ¹æ®å¤æ‚åº¦ã€å»¶è¿Ÿè¦æ±‚ã€æˆæœ¬é¢„ç®—è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹

**æ•ˆæœå¯¹æ¯”**ï¼š

| æŒ‡æ ‡      | ä¼˜åŒ–å‰             | ä¼˜åŒ–å             | æå‡å¹…åº¦     |
| ------- | --------------- | --------------- | -------- |
| P95 å»¶è¿Ÿ  | 5000ms          | 1500ms          | â¬‡ï¸ 70%   |
| æ¨ç†æˆæœ¬    | $1.00/1K tokens | $0.40/1K tokens | â¬‡ï¸ 60%   |
| GPU åˆ©ç”¨ç‡ | 40%             | 75%             | â¬†ï¸ 87.5% |

```

**File:** README-zh.md (L176-264)
```markdown

OpenEAAP é‡‡ç”¨ç»å…¸çš„ **DDDï¼ˆé¢†åŸŸé©±åŠ¨è®¾è®¡ï¼‰åˆ†å±‚æ¶æ„**ï¼Œæ¸…æ™°çš„èŒè´£åˆ’åˆ†ç¡®ä¿ç³»ç»Ÿçš„å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ã€‚

```mermaid
graph TB
    subgraph API[æ¥å£å±‚ï¼ˆInterface Layerï¼‰]
        HTTP[HTTP API<br/>REST/GraphQL]
        GRPC[gRPC API<br/>é«˜æ€§èƒ½RPC]
        CLI[CLIå·¥å…·<br/>å‘½ä»¤è¡Œç®¡ç†]
    end
    
    subgraph APP[åº”ç”¨å±‚ï¼ˆApplication Layerï¼‰]
        SERVICE1[AgentæœåŠ¡<br/>Agent Service]
        SERVICE2[WorkflowæœåŠ¡<br/>Workflow Service]
        SERVICE3[ModelæœåŠ¡<br/>Model Service]
        SERVICE4[DataæœåŠ¡<br/>Data Service]
    end
    
    subgraph PLATFORM[å¹³å°å±‚ï¼ˆPlatform Layerï¼‰]
        ORCH[ç¼–æ’å™¨<br/>Orchestrator]
        RUNTIME[è¿è¡Œæ—¶<br/>Runtime]
        INFERENCE[æ¨ç†å¼•æ“<br/>Inference Engine]
        RAG[RAGå¼•æ“<br/>RAG Engine]
        LEARNING[åœ¨çº¿å­¦ä¹ <br/>Online Learning]
        TRAINING[è®­ç»ƒæœåŠ¡<br/>Training Service]
    end
    
    subgraph DOMAIN[é¢†åŸŸå±‚ï¼ˆDomain Layerï¼‰]
        AGENT_D[Agenté¢†åŸŸ<br/>Agent Domain]
        WORKFLOW_D[Workflowé¢†åŸŸ<br/>Workflow Domain]
        MODEL_D[Modelé¢†åŸŸ<br/>Model Domain]
        KNOWLEDGE_D[Knowledgeé¢†åŸŸ<br/>Knowledge Domain]
    end
    
    subgraph INFRA[åŸºç¡€è®¾æ–½å±‚ï¼ˆInfrastructure Layerï¼‰]
        REPO[ä»“å‚¨å®ç°<br/>Repository]
        VECTOR[å‘é‡æ•°æ®åº“<br/>Vector DB]
        STORAGE[å¯¹è±¡å­˜å‚¨<br/>Object Storage]
        MQ[æ¶ˆæ¯é˜Ÿåˆ—<br/>Message Queue]
    end
    
    subgraph GOV[æ²»ç†å±‚ï¼ˆGovernance Layerï¼‰]
        POLICY[ç­–ç•¥å¼•æ“<br/>Policy Engine]
        AUDIT[å®¡è®¡<br/>Audit]
        COMPLIANCE[åˆè§„<br/>Compliance]
    end
    
    subgraph OBS[å¯è§‚æµ‹æ€§å±‚ï¼ˆObservability Layerï¼‰]
        TRACE[åˆ†å¸ƒå¼è¿½è¸ª<br/>Tracing]
        METRICS[æŒ‡æ ‡æ”¶é›†<br/>Metrics]
        LOGGING[æ—¥å¿—<br/>Logging]
    end
    
    API --> APP
    APP --> PLATFORM
    APP --> DOMAIN
    PLATFORM --> DOMAIN
    DOMAIN --> INFRA
    
    GOV -.æ¨ªåˆ‡.-> PLATFORM
    GOV -.æ¨ªåˆ‡.-> APP
    OBS -.æ¨ªåˆ‡.-> PLATFORM
    OBS -.æ¨ªåˆ‡.-> APP
    
    style API fill:#e1f5fe
    style APP fill:#f3e5f5
    style PLATFORM fill:#fff9c4
    style DOMAIN fill:#c8e6c9
    style INFRA fill:#ffccbc
    style GOV fill:#ffebee
    style OBS fill:#f0f4c3
```

**å„å±‚èŒè´£**ï¼š

| å±‚æ¬¡        | èŒè´£                 | ç¤ºä¾‹ç»„ä»¶                                     |
| --------- | ------------------ | ---------------------------------------- |
| **æ¥å£å±‚**   | å¯¹å¤–æš´éœ² APIï¼Œå¤„ç†è¯·æ±‚/å“åº”   | HTTP Handlerã€gRPC Serverã€CLI å‘½ä»¤          |
| **åº”ç”¨å±‚**   | ç¼–æ’ä¸šåŠ¡æµç¨‹ï¼Œåè°ƒå¤šä¸ªé¢†åŸŸæœåŠ¡    | AgentServiceã€WorkflowService             |
| **å¹³å°å±‚**   | æ ¸å¿ƒèƒ½åŠ›ç»„ä»¶ï¼Œç¼–æ’ã€æ¨ç†ã€RAG ç­‰ | Orchestratorã€Inference Engineã€RAG Engine |
| **é¢†åŸŸå±‚**   | ä¸šåŠ¡æ ¸å¿ƒé€»è¾‘ï¼Œé¢†åŸŸå®ä½“å’Œé¢†åŸŸæœåŠ¡   | Agentã€Workflowã€Model å®ä½“å’Œé¢†åŸŸæœåŠ¡             |
| **åŸºç¡€è®¾æ–½å±‚** | æ•°æ®æŒä¹…åŒ–å’Œå¤–éƒ¨ç³»ç»Ÿé›†æˆ       | PostgreSQLã€Redisã€Milvusã€MinIO            |
| **æ²»ç†å±‚**   | å®‰å…¨ã€åˆè§„ã€å®¡è®¡           | ç­–ç•¥å¼•æ“ã€å®¡è®¡æ—¥å¿—ã€PII æ£€æµ‹                         |
| **å¯è§‚æµ‹æ€§å±‚** | ç›‘æ§ã€è¿½è¸ªã€æ—¥å¿—           | OpenTelemetryã€Prometheusã€Loki            |

### æ ¸å¿ƒç»„ä»¶äº¤äº’æµç¨‹

ä»¥ä¸‹æ—¶åºå›¾å±•ç¤ºäº†ä¸€æ¬¡å®Œæ•´çš„ Agent æ‰§è¡Œè¯·æ±‚çš„å¤„ç†æµç¨‹ï¼š

```

**File:** README-zh.md (L614-650)
```markdown
## ğŸ—ºï¸ è·¯çº¿å›¾

### Phase 1: åŸºç¡€å¹³å°ï¼ˆ2026 Q1-Q2ï¼‰âœ…

* [x] æ ¸å¿ƒæ¡†æ¶æ­å»ºï¼ˆDDD æ¶æ„ï¼‰
* [x] ç¼–æ’å™¨ä¸è¿è¡Œæ—¶ï¼ˆNativeã€LangChain é€‚é…å™¨ï¼‰
* [x] æ¨ç†ç½‘å…³ï¼ˆvLLM é›†æˆï¼‰
* [x] ä¸‰çº§ç¼“å­˜æ¶æ„

### Phase 2: æ•°æ®æ™ºèƒ½ï¼ˆ2026 Q2-Q3ï¼‰ğŸš§

* [ ] RAG å¼•æ“ï¼ˆæ··åˆæ£€ç´¢ã€é‡æ’åºï¼‰
* [ ] å‘é‡æ•°æ®åº“é›†æˆï¼ˆMilvusï¼‰
* [ ] çŸ¥è¯†å›¾è°±æ„å»º
* [ ] æ–‡æ¡£å¤„ç†æµæ°´çº¿ï¼ˆè§£æã€åˆ†å—ã€å‘é‡åŒ–ï¼‰

### Phase 3: æŒç»­ä¼˜åŒ–ï¼ˆ2026 Q3-Q4ï¼‰ğŸ“…

* [ ] åœ¨çº¿å­¦ä¹ å¼•æ“
* [ ] RLHF/DPO è®­ç»ƒæµç¨‹
* [ ] Prompt è‡ªåŠ¨ä¼˜åŒ–
* [ ] A/B æµ‹è¯•æ¡†æ¶

### Phase 4: æ²»ç†å¢å¼ºï¼ˆ2026 Q4-2027 Q1ï¼‰ğŸ“…

* [ ] ç­–ç•¥å¼•æ“ï¼ˆABAC/RBACï¼‰
* [ ] éšç§è®¡ç®—ç½‘å…³ï¼ˆPII æ£€æµ‹ä¸è„±æ•ï¼‰
* [ ] å®¡è®¡ä¸åˆè§„ï¼ˆSOC2ã€GDPRï¼‰
* [ ] æ¼æ´æ‰«æä¸å®‰å…¨åŠ å›º

### Phase 5: ç”Ÿæ€é›†æˆï¼ˆ2027 Q1-Q2ï¼‰ğŸ“…

* [ ] AutoGPT é€‚é…å™¨
* [ ] æ’ä»¶å¸‚åœº
* [ ] å¤šæ¨¡æ€æ”¯æŒï¼ˆå›¾åƒã€è¯­éŸ³ï¼‰
* [ ] è¾¹ç¼˜ AI éƒ¨ç½²

```

**File:** internal/platform/rag/rag_engine.go (L14-106)
```go
// RAGEngine å®šä¹‰ RAG å¼•æ“æ¥å£
type RAGEngine interface {
	// Query æ‰§è¡Œå®Œæ•´çš„ RAG æŸ¥è¯¢æµç¨‹
	Query(ctx context.Context, req *RAGRequest) (*RAGResponse, error)

	// QueryStream æ‰§è¡Œæµå¼ RAG æŸ¥è¯¢
	QueryStream(ctx context.Context, req *RAGRequest) (<-chan *RAGChunk, error)

	// HealthCheck å¥åº·æ£€æŸ¥
	HealthCheck(ctx context.Context) error
}

// RAGRequest å®šä¹‰ RAG è¯·æ±‚
type RAGRequest struct {
	Query           string            // ç”¨æˆ·æŸ¥è¯¢
	CollectionName  string            // çŸ¥è¯†åº“åç§°
	TopK            int               // æ£€ç´¢æ•°é‡
	RetrievalMode   RetrievalMode     // æ£€ç´¢æ¨¡å¼
	RerankEnabled   bool              // æ˜¯å¦å¯ç”¨é‡æ’åº
	ModelName       string            // ç”Ÿæˆæ¨¡å‹åç§°
	Temperature     float32           // ç”Ÿæˆæ¸©åº¦
	MaxTokens       int               // æœ€å¤§ç”Ÿæˆé•¿åº¦
	Metadata        map[string]string // å…ƒæ•°æ®è¿‡æ»¤
	VerifyEnabled   bool              // æ˜¯å¦å¯ç”¨ç­”æ¡ˆéªŒè¯
}

// RAGResponse å®šä¹‰ RAG å“åº”
type RAGResponse struct {
	Answer          string              // ç”Ÿæˆçš„ç­”æ¡ˆ
	RetrievedChunks []*RetrievedChunk   // æ£€ç´¢åˆ°çš„æ–‡æ¡£å—
	Sources         []string            // å¼•ç”¨æ¥æº
	Confidence      float32             // ç½®ä¿¡åº¦
	Latency         LatencyBreakdown    // å»¶è¿Ÿåˆ†è§£
	Verified        bool                // æ˜¯å¦é€šè¿‡éªŒè¯
	VerifyResult    *VerifyResult       // éªŒè¯ç»“æœ
}

// RAGChunk å®šä¹‰æµå¼å“åº”å—
type RAGChunk struct {
	Type    ChunkType // å—ç±»å‹
	Content string    // å†…å®¹
	Done    bool      // æ˜¯å¦å®Œæˆ
	Error   error     // é”™è¯¯
}

// ChunkType å®šä¹‰å—ç±»å‹
type ChunkType string

const (
	ChunkTypeRetrieval ChunkType = "retrieval" // æ£€ç´¢é˜¶æ®µ
	ChunkTypeGenerate  ChunkType = "generate"  // ç”Ÿæˆé˜¶æ®µ
	ChunkTypeVerify    ChunkType = "verify"    // éªŒè¯é˜¶æ®µ
	ChunkTypeError     ChunkType = "error"     // é”™è¯¯
)

// RetrievalMode å®šä¹‰æ£€ç´¢æ¨¡å¼
type RetrievalMode string

const (
	RetrievalModeVector  RetrievalMode = "vector"  // å‘é‡æ£€ç´¢
	RetrievalModeKeyword RetrievalMode = "keyword" // å…³é”®è¯æ£€ç´¢
	RetrievalModeHybrid  RetrievalMode = "hybrid"  // æ··åˆæ£€ç´¢
	RetrievalModeGraph   RetrievalMode = "graph"   // çŸ¥è¯†å›¾è°±æ£€ç´¢
)

// RetrievedChunk å®šä¹‰æ£€ç´¢åˆ°çš„æ–‡æ¡£å—
type RetrievedChunk struct {
	ChunkID    string            // å—ID
	DocumentID string            // æ–‡æ¡£ID
	Content    string            // å†…å®¹
	Score      float32           // ç›¸å…³æ€§åˆ†æ•°
	Metadata   map[string]string // å…ƒæ•°æ®
	Source     string            // æ¥æº
}

// LatencyBreakdown å®šä¹‰å»¶è¿Ÿåˆ†è§£
type LatencyBreakdown struct {
	QueryUnderstanding time.Duration // æŸ¥è¯¢ç†è§£
	Retrieval          time.Duration // æ£€ç´¢
	Reranking          time.Duration // é‡æ’åº
	ContextBuilding    time.Duration // ä¸Šä¸‹æ–‡æ„å»º
	Generation         time.Duration // ç”Ÿæˆ
	Verification       time.Duration // éªŒè¯
	Total              time.Duration // æ€»å»¶è¿Ÿ
}

// VerifyResult å®šä¹‰éªŒè¯ç»“æœ
type VerifyResult struct {
	HasHallucination bool     // æ˜¯å¦å­˜åœ¨å¹»è§‰
	CitationValid    bool     // å¼•ç”¨æ˜¯å¦æœ‰æ•ˆ
	FactCheckPassed  bool     // äº‹å®æ£€æŸ¥æ˜¯å¦é€šè¿‡
	Issues           []string // é—®é¢˜åˆ—è¡¨
}
```

**File:** internal/platform/rag/rag_engine.go (L154-259)
```go
// Query æ‰§è¡Œå®Œæ•´çš„ RAG æŸ¥è¯¢æµç¨‹
func (r *ragEngineImpl) Query(ctx context.Context, req *RAGRequest) (*RAGResponse, error) {
	startTime := time.Now()

	// åˆ›å»º Span
	span := r.tracer.StartSpan(ctx, "RAGEngine.Query")
	defer span.End()
	span.AddTag("query", req.Query)
	span.AddTag("collection", req.CollectionName)

	// åº”ç”¨é»˜è®¤å€¼
	r.applyDefaults(req)

	// éªŒè¯è¯·æ±‚
	if err := r.validateRequest(req); err != nil {
		return nil, errors.Wrap(err, errors.CodeInvalidArgument, "invalid RAG request")
	}

	var latency LatencyBreakdown

	// 1. æŸ¥è¯¢ç†è§£ï¼ˆå¯é€‰ï¼Œå½“å‰ç®€åŒ–ä¸ºç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼‰
	queryStart := time.Now()
	processedQuery := r.understandQuery(ctx, req.Query)
	latency.QueryUnderstanding = time.Since(queryStart)

	// 2. æ£€ç´¢é˜¶æ®µ
	retrievalStart := time.Now()
	retrievedChunks, err := r.retrieveChunks(ctx, processedQuery, req)
	if err != nil {
		span.SetStatus(trace.StatusError, err.Error())
		return nil, errors.Wrap(err, errors.CodeInternal, "retrieval failed")
	}
	latency.Retrieval = time.Since(retrievalStart)

	r.logger.Info(ctx, "retrieval completed",
		"query", req.Query,
		"chunks_count", len(retrievedChunks),
		"latency_ms", latency.Retrieval.Milliseconds())

	// 3. é‡æ’åºé˜¶æ®µï¼ˆå¯é€‰ï¼‰
	if req.RerankEnabled && r.reranker != nil {
		rerankStart := time.Now()
		retrievedChunks, err = r.rerankChunks(ctx, processedQuery, retrievedChunks)
		if err != nil {
			r.logger.Warn(ctx, "reranking failed, using original order", "error", err)
		}
		latency.Reranking = time.Since(rerankStart)
	}

	// 4. ä¸Šä¸‹æ–‡æ„å»ºé˜¶æ®µ
	contextStart := time.Now()
	ragContext := r.buildContext(ctx, retrievedChunks, req)
	latency.ContextBuilding = time.Since(contextStart)

	// 5. ç”Ÿæˆé˜¶æ®µ
	generationStart := time.Now()
	answer, sources, err := r.generateAnswer(ctx, req.Query, ragContext, req)
	if err != nil {
		span.SetStatus(trace.StatusError, err.Error())
		return nil, errors.Wrap(err, errors.CodeInternal, "generation failed")
	}
	latency.Generation = time.Since(generationStart)

	// 6. éªŒè¯é˜¶æ®µï¼ˆå¯é€‰ï¼‰
	var verifyResult *VerifyResult
	verified := true
	if req.VerifyEnabled {
		verifyStart := time.Now()
		verifyResult, err = r.verifyAnswer(ctx, req.Query, answer, retrievedChunks)
		if err != nil {
			r.logger.Warn(ctx, "verification failed", "error", err)
		} else {
			verified = verifyResult.HasHallucination == false &&
				verifyResult.CitationValid &&
				verifyResult.FactCheckPassed
		}
		latency.Verification = time.Since(verifyStart)
	}

	latency.Total = time.Since(startTime)

	// è®¡ç®—ç½®ä¿¡åº¦
	confidence := r.calculateConfidence(retrievedChunks, verified)

	response := &RAGResponse{
		Answer:          answer,
		RetrievedChunks: retrievedChunks,
		Sources:         sources,
		Confidence:      confidence,
		Latency:         latency,
		Verified:        verified,
		VerifyResult:    verifyResult,
	}

	r.logger.Info(ctx, "RAG query completed",
		"query", req.Query,
		"answer_length", len(answer),
		"confidence", confidence,
		"verified", verified,
		"total_latency_ms", latency.Total.Milliseconds())

	span.AddTag("confidence", fmt.Sprintf("%.2f", confidence))
	span.AddTag("verified", verified)

	return response, nil
}
```

**File:** internal/platform/rag/rag_engine.go (L261-341)
```go
// QueryStream æ‰§è¡Œæµå¼ RAG æŸ¥è¯¢
func (r *ragEngineImpl) QueryStream(ctx context.Context, req *RAGRequest) (<-chan *RAGChunk, error) {
	chunkChan := make(chan *RAGChunk, 10)

	go func() {
		defer close(chunkChan)

		// åº”ç”¨é»˜è®¤å€¼
		r.applyDefaults(req)

		// 1. æ£€ç´¢é˜¶æ®µ
		chunkChan <- &RAGChunk{Type: ChunkTypeRetrieval, Content: "å¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£...", Done: false}

		processedQuery := r.understandQuery(ctx, req.Query)
		retrievedChunks, err := r.retrieveChunks(ctx, processedQuery, req)
		if err != nil {
			chunkChan <- &RAGChunk{Type: ChunkTypeError, Error: err, Done: true}
			return
		}

		chunkChan <- &RAGChunk{
			Type:    ChunkTypeRetrieval,
			Content: fmt.Sprintf("æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° %d ä¸ªç›¸å…³æ–‡æ¡£å—", len(retrievedChunks)),
			Done:    false,
		}

		// 2. é‡æ’åºï¼ˆå¯é€‰ï¼‰
		if req.RerankEnabled && r.reranker != nil {
			retrievedChunks, _ = r.rerankChunks(ctx, processedQuery, retrievedChunks)
		}

		// 3. æ„å»ºä¸Šä¸‹æ–‡
		ragContext := r.buildContext(ctx, retrievedChunks, req)

		// 4. æµå¼ç”Ÿæˆ
		chunkChan <- &RAGChunk{Type: ChunkTypeGenerate, Content: "", Done: false}

		answerChan, err := r.generator.GenerateStream(ctx, &GenerateRequest{
			Query:       req.Query,
			Context:     ragContext,
			ModelName:   req.ModelName,
			Temperature: req.Temperature,
			MaxTokens:   req.MaxTokens,
		})

		if err != nil {
			chunkChan <- &RAGChunk{Type: ChunkTypeError, Error: err, Done: true}
			return
		}

		fullAnswer := ""
		for genChunk := range answerChan {
			if genChunk.Error != nil {
				chunkChan <- &RAGChunk{Type: ChunkTypeError, Error: genChunk.Error, Done: true}
				return
			}
			fullAnswer += genChunk.Content
			chunkChan <- &RAGChunk{Type: ChunkTypeGenerate, Content: genChunk.Content, Done: false}
		}

		// 5. éªŒè¯ï¼ˆå¯é€‰ï¼‰
		if req.VerifyEnabled {
			chunkChan <- &RAGChunk{Type: ChunkTypeVerify, Content: "éªŒè¯ç­”æ¡ˆä¸­...", Done: false}
			verifyResult, err := r.verifyAnswer(ctx, req.Query, fullAnswer, retrievedChunks)
			if err == nil {
				verified := verifyResult.HasHallucination == false &&
					verifyResult.CitationValid &&
					verifyResult.FactCheckPassed
				chunkChan <- &RAGChunk{
					Type:    ChunkTypeVerify,
					Content: fmt.Sprintf("éªŒè¯å®Œæˆï¼Œç»“æœ: %v", verified),
					Done:    true,
				}
			}
		} else {
			chunkChan <- &RAGChunk{Type: ChunkTypeGenerate, Content: "", Done: true}
		}
	}()

	return chunkChan, nil
}
```

**File:** internal/platform/rag/rag_engine.go (L389-410)
```go
// buildContext æ„å»º RAG ä¸Šä¸‹æ–‡
func (r *ragEngineImpl) buildContext(ctx context.Context, chunks []*RetrievedChunk, req *RAGRequest) string {
	var contextBuilder string
	currentLength := 0

	for i, chunk := range chunks {
		chunkText := fmt.Sprintf("[æ–‡æ¡£ %d] æ¥æº: %s\n%s\n\n", i+1, chunk.Source, chunk.Content)

		// æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
		if currentLength+len(chunkText) > r.config.MaxContextLength {
			r.logger.Warn(ctx, "context truncated due to length limit",
				"max_length", r.config.MaxContextLength,
				"chunks_included", i)
			break
		}

		contextBuilder += chunkText
		currentLength += len(chunkText)
	}

	return contextBuilder
}
```

**File:** internal/platform/rag/rag_engine.go (L431-461)
```go
func (r *ragEngineImpl) verifyAnswer(ctx context.Context, query, answer string, chunks []*RetrievedChunk) (*VerifyResult, error) {
	// ç®€åŒ–å®ç°ï¼šåŸºäºè§„åˆ™çš„éªŒè¯
	result := &VerifyResult{
		HasHallucination: false,
		CitationValid:    true,
		FactCheckPassed:  true,
		Issues:           []string{},
	}

	// æ£€æŸ¥ç­”æ¡ˆé•¿åº¦
	if len(answer) < 10 {
		result.Issues = append(result.Issues, "ç­”æ¡ˆè¿‡çŸ­")
		result.FactCheckPassed = false
	}

	// æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†æ£€ç´¢åˆ°çš„å†…å®¹
	hasReference := false
	for _, chunk := range chunks {
		if contains(answer, chunk.Content[:min(50, len(chunk.Content))]) {
			hasReference = true
			break
		}
	}

	if !hasReference {
		result.Issues = append(result.Issues, "ç­”æ¡ˆæœªå¼•ç”¨æ£€ç´¢åˆ°çš„å†…å®¹ï¼Œå¯èƒ½å­˜åœ¨å¹»è§‰")
		result.HasHallucination = true
	}

	return result, nil
}
```
