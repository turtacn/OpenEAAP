// api/proto/model.proto
// OpenEAAP Model Service gRPC Protocol Buffers Definition
// Defines ModelService, Model, ModelConfig and related messages for model management

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.21.12
// source: model.proto

package modelpb

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	structpb "google.golang.org/protobuf/types/known/structpb"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// ModelType defines the type of model
type ModelType int32

const (
	ModelType_MODEL_TYPE_UNSPECIFIED ModelType = 0
	ModelType_MODEL_TYPE_LLM         ModelType = 1 // Large Language Model
	ModelType_MODEL_TYPE_EMBEDDING   ModelType = 2 // Embedding Model
	ModelType_MODEL_TYPE_RERANKER    ModelType = 3 // Reranking Model
	ModelType_MODEL_TYPE_CLASSIFIER  ModelType = 4 // Classification Model
	ModelType_MODEL_TYPE_VISION      ModelType = 5 // Vision Model
	ModelType_MODEL_TYPE_MULTIMODAL  ModelType = 6 // Multimodal Model
)

// Enum value maps for ModelType.
var (
	ModelType_name = map[int32]string{
		0: "MODEL_TYPE_UNSPECIFIED",
		1: "MODEL_TYPE_LLM",
		2: "MODEL_TYPE_EMBEDDING",
		3: "MODEL_TYPE_RERANKER",
		4: "MODEL_TYPE_CLASSIFIER",
		5: "MODEL_TYPE_VISION",
		6: "MODEL_TYPE_MULTIMODAL",
	}
	ModelType_value = map[string]int32{
		"MODEL_TYPE_UNSPECIFIED": 0,
		"MODEL_TYPE_LLM":         1,
		"MODEL_TYPE_EMBEDDING":   2,
		"MODEL_TYPE_RERANKER":    3,
		"MODEL_TYPE_CLASSIFIER":  4,
		"MODEL_TYPE_VISION":      5,
		"MODEL_TYPE_MULTIMODAL":  6,
	}
)

func (x ModelType) Enum() *ModelType {
	p := new(ModelType)
	*p = x
	return p
}

func (x ModelType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ModelType) Descriptor() protoreflect.EnumDescriptor {
	return file_model_proto_enumTypes[0].Descriptor()
}

func (ModelType) Type() protoreflect.EnumType {
	return &file_model_proto_enumTypes[0]
}

func (x ModelType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ModelType.Descriptor instead.
func (ModelType) EnumDescriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{0}
}

// DeploymentStatus defines model deployment status
type DeploymentStatus int32

const (
	DeploymentStatus_DEPLOYMENT_STATUS_UNSPECIFIED DeploymentStatus = 0
	DeploymentStatus_DEPLOYMENT_STATUS_REGISTERED  DeploymentStatus = 1 // Registered but not deployed
	DeploymentStatus_DEPLOYMENT_STATUS_DEPLOYING   DeploymentStatus = 2 // Deployment in progress
	DeploymentStatus_DEPLOYMENT_STATUS_DEPLOYED    DeploymentStatus = 3 // Successfully deployed
	DeploymentStatus_DEPLOYMENT_STATUS_FAILED      DeploymentStatus = 4 // Deployment failed
	DeploymentStatus_DEPLOYMENT_STATUS_UNDEPLOYING DeploymentStatus = 5 // Undeployment in progress
	DeploymentStatus_DEPLOYMENT_STATUS_UNDEPLOYED  DeploymentStatus = 6 // Successfully undeployed
	DeploymentStatus_DEPLOYMENT_STATUS_UNHEALTHY   DeploymentStatus = 7 // Deployed but unhealthy
)

// Enum value maps for DeploymentStatus.
var (
	DeploymentStatus_name = map[int32]string{
		0: "DEPLOYMENT_STATUS_UNSPECIFIED",
		1: "DEPLOYMENT_STATUS_REGISTERED",
		2: "DEPLOYMENT_STATUS_DEPLOYING",
		3: "DEPLOYMENT_STATUS_DEPLOYED",
		4: "DEPLOYMENT_STATUS_FAILED",
		5: "DEPLOYMENT_STATUS_UNDEPLOYING",
		6: "DEPLOYMENT_STATUS_UNDEPLOYED",
		7: "DEPLOYMENT_STATUS_UNHEALTHY",
	}
	DeploymentStatus_value = map[string]int32{
		"DEPLOYMENT_STATUS_UNSPECIFIED": 0,
		"DEPLOYMENT_STATUS_REGISTERED":  1,
		"DEPLOYMENT_STATUS_DEPLOYING":   2,
		"DEPLOYMENT_STATUS_DEPLOYED":    3,
		"DEPLOYMENT_STATUS_FAILED":      4,
		"DEPLOYMENT_STATUS_UNDEPLOYING": 5,
		"DEPLOYMENT_STATUS_UNDEPLOYED":  6,
		"DEPLOYMENT_STATUS_UNHEALTHY":   7,
	}
)

func (x DeploymentStatus) Enum() *DeploymentStatus {
	p := new(DeploymentStatus)
	*p = x
	return p
}

func (x DeploymentStatus) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (DeploymentStatus) Descriptor() protoreflect.EnumDescriptor {
	return file_model_proto_enumTypes[1].Descriptor()
}

func (DeploymentStatus) Type() protoreflect.EnumType {
	return &file_model_proto_enumTypes[1]
}

func (x DeploymentStatus) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use DeploymentStatus.Descriptor instead.
func (DeploymentStatus) EnumDescriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{1}
}

// Model represents a machine learning model entity
type Model struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique model identifier
	Id string `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Model name (must be unique)
	Name string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	// Model type (e.g., LLM, EMBEDDING, RERANKER)
	Type ModelType `protobuf:"varint,3,opt,name=type,proto3,enum=openeeap.model.v1.ModelType" json:"type,omitempty"`
	// Model version (semantic versioning)
	Version string `protobuf:"bytes,4,opt,name=version,proto3" json:"version,omitempty"`
	// Human-readable description
	Description string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	// Model configuration
	Config *ModelConfig `protobuf:"bytes,6,opt,name=config,proto3" json:"config,omitempty"`
	// Model capabilities
	Capabilities *ModelCapabilities `protobuf:"bytes,7,opt,name=capabilities,proto3" json:"capabilities,omitempty"`
	// Model resource requirements
	Resources *ResourceRequirements `protobuf:"bytes,8,opt,name=resources,proto3" json:"resources,omitempty"`
	// Current deployment status
	Status DeploymentStatus `protobuf:"varint,9,opt,name=status,proto3,enum=openeeap.model.v1.DeploymentStatus" json:"status,omitempty"`
	// Model endpoint (if deployed)
	Endpoint string `protobuf:"bytes,10,opt,name=endpoint,proto3" json:"endpoint,omitempty"`
	// Model provider (e.g., OPENAI, ANTHROPIC, VLLM)
	Provider string `protobuf:"bytes,11,opt,name=provider,proto3" json:"provider,omitempty"`
	// Cost per 1K tokens (in USD)
	CostPer_1KTokens float64 `protobuf:"fixed64,12,opt,name=cost_per_1k_tokens,json=costPer1kTokens,proto3" json:"cost_per_1k_tokens,omitempty"`
	// Model metadata (tags, labels, etc.)
	Metadata map[string]string `protobuf:"bytes,13,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Creation timestamp
	CreatedAt *timestamppb.Timestamp `protobuf:"bytes,14,opt,name=created_at,json=createdAt,proto3" json:"created_at,omitempty"`
	// Last update timestamp
	UpdatedAt *timestamppb.Timestamp `protobuf:"bytes,15,opt,name=updated_at,json=updatedAt,proto3" json:"updated_at,omitempty"`
	// Created by user ID
	CreatedBy     string `protobuf:"bytes,16,opt,name=created_by,json=createdBy,proto3" json:"created_by,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Model) Reset() {
	*x = Model{}
	mi := &file_model_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Model) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Model) ProtoMessage() {}

func (x *Model) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Model.ProtoReflect.Descriptor instead.
func (*Model) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{0}
}

func (x *Model) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *Model) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Model) GetType() ModelType {
	if x != nil {
		return x.Type
	}
	return ModelType_MODEL_TYPE_UNSPECIFIED
}

func (x *Model) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *Model) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Model) GetConfig() *ModelConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *Model) GetCapabilities() *ModelCapabilities {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

func (x *Model) GetResources() *ResourceRequirements {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *Model) GetStatus() DeploymentStatus {
	if x != nil {
		return x.Status
	}
	return DeploymentStatus_DEPLOYMENT_STATUS_UNSPECIFIED
}

func (x *Model) GetEndpoint() string {
	if x != nil {
		return x.Endpoint
	}
	return ""
}

func (x *Model) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *Model) GetCostPer_1KTokens() float64 {
	if x != nil {
		return x.CostPer_1KTokens
	}
	return 0
}

func (x *Model) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *Model) GetCreatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.CreatedAt
	}
	return nil
}

func (x *Model) GetUpdatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdatedAt
	}
	return nil
}

func (x *Model) GetCreatedBy() string {
	if x != nil {
		return x.CreatedBy
	}
	return ""
}

// ModelConfig contains model-specific configuration
type ModelConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Model file path or URL
	ModelPath string `protobuf:"bytes,1,opt,name=model_path,json=modelPath,proto3" json:"model_path,omitempty"`
	// Inference engine (VLLM, TGI, TENSORRT, etc.)
	InferenceEngine string `protobuf:"bytes,2,opt,name=inference_engine,json=inferenceEngine,proto3" json:"inference_engine,omitempty"`
	// Inference parameters
	InferenceConfig *InferenceConfig `protobuf:"bytes,3,opt,name=inference_config,json=inferenceConfig,proto3" json:"inference_config,omitempty"`
	// Quantization settings
	Quantization *QuantizationConfig `protobuf:"bytes,4,opt,name=quantization,proto3" json:"quantization,omitempty"`
	// Tokenizer configuration
	Tokenizer *TokenizerConfig `protobuf:"bytes,5,opt,name=tokenizer,proto3" json:"tokenizer,omitempty"`
	// Custom configuration (engine-specific)
	CustomConfig  *structpb.Struct `protobuf:"bytes,6,opt,name=custom_config,json=customConfig,proto3" json:"custom_config,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelConfig) Reset() {
	*x = ModelConfig{}
	mi := &file_model_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelConfig) ProtoMessage() {}

func (x *ModelConfig) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelConfig.ProtoReflect.Descriptor instead.
func (*ModelConfig) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{1}
}

func (x *ModelConfig) GetModelPath() string {
	if x != nil {
		return x.ModelPath
	}
	return ""
}

func (x *ModelConfig) GetInferenceEngine() string {
	if x != nil {
		return x.InferenceEngine
	}
	return ""
}

func (x *ModelConfig) GetInferenceConfig() *InferenceConfig {
	if x != nil {
		return x.InferenceConfig
	}
	return nil
}

func (x *ModelConfig) GetQuantization() *QuantizationConfig {
	if x != nil {
		return x.Quantization
	}
	return nil
}

func (x *ModelConfig) GetTokenizer() *TokenizerConfig {
	if x != nil {
		return x.Tokenizer
	}
	return nil
}

func (x *ModelConfig) GetCustomConfig() *structpb.Struct {
	if x != nil {
		return x.CustomConfig
	}
	return nil
}

// InferenceConfig defines inference parameters
type InferenceConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Maximum sequence length
	MaxSeqLength int32 `protobuf:"varint,1,opt,name=max_seq_length,json=maxSeqLength,proto3" json:"max_seq_length,omitempty"`
	// Batch size for inference
	BatchSize int32 `protobuf:"varint,2,opt,name=batch_size,json=batchSize,proto3" json:"batch_size,omitempty"`
	// GPU memory utilization (0.0 - 1.0)
	GpuMemoryUtilization float32 `protobuf:"fixed32,3,opt,name=gpu_memory_utilization,json=gpuMemoryUtilization,proto3" json:"gpu_memory_utilization,omitempty"`
	// Enable KV cache
	EnableKvCache bool `protobuf:"varint,4,opt,name=enable_kv_cache,json=enableKvCache,proto3" json:"enable_kv_cache,omitempty"`
	// Tensor parallelism degree
	TensorParallelSize int32 `protobuf:"varint,5,opt,name=tensor_parallel_size,json=tensorParallelSize,proto3" json:"tensor_parallel_size,omitempty"`
	// Pipeline parallelism degree
	PipelineParallelSize int32 `protobuf:"varint,6,opt,name=pipeline_parallel_size,json=pipelineParallelSize,proto3" json:"pipeline_parallel_size,omitempty"`
	// Default temperature
	DefaultTemperature float32 `protobuf:"fixed32,7,opt,name=default_temperature,json=defaultTemperature,proto3" json:"default_temperature,omitempty"`
	// Default top_p
	DefaultTopP float32 `protobuf:"fixed32,8,opt,name=default_top_p,json=defaultTopP,proto3" json:"default_top_p,omitempty"`
	// Default max_tokens
	DefaultMaxTokens int32 `protobuf:"varint,9,opt,name=default_max_tokens,json=defaultMaxTokens,proto3" json:"default_max_tokens,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *InferenceConfig) Reset() {
	*x = InferenceConfig{}
	mi := &file_model_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceConfig) ProtoMessage() {}

func (x *InferenceConfig) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceConfig.ProtoReflect.Descriptor instead.
func (*InferenceConfig) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{2}
}

func (x *InferenceConfig) GetMaxSeqLength() int32 {
	if x != nil {
		return x.MaxSeqLength
	}
	return 0
}

func (x *InferenceConfig) GetBatchSize() int32 {
	if x != nil {
		return x.BatchSize
	}
	return 0
}

func (x *InferenceConfig) GetGpuMemoryUtilization() float32 {
	if x != nil {
		return x.GpuMemoryUtilization
	}
	return 0
}

func (x *InferenceConfig) GetEnableKvCache() bool {
	if x != nil {
		return x.EnableKvCache
	}
	return false
}

func (x *InferenceConfig) GetTensorParallelSize() int32 {
	if x != nil {
		return x.TensorParallelSize
	}
	return 0
}

func (x *InferenceConfig) GetPipelineParallelSize() int32 {
	if x != nil {
		return x.PipelineParallelSize
	}
	return 0
}

func (x *InferenceConfig) GetDefaultTemperature() float32 {
	if x != nil {
		return x.DefaultTemperature
	}
	return 0
}

func (x *InferenceConfig) GetDefaultTopP() float32 {
	if x != nil {
		return x.DefaultTopP
	}
	return 0
}

func (x *InferenceConfig) GetDefaultMaxTokens() int32 {
	if x != nil {
		return x.DefaultMaxTokens
	}
	return 0
}

// QuantizationConfig defines model quantization settings
type QuantizationConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Enable quantization
	Enabled bool `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
	// Quantization method (AWQ, GPTQ, SmoothQuant, etc.)
	Method string `protobuf:"bytes,2,opt,name=method,proto3" json:"method,omitempty"`
	// Quantization bits (4, 8, 16)
	Bits int32 `protobuf:"varint,3,opt,name=bits,proto3" json:"bits,omitempty"`
	// Group size for quantization
	GroupSize     int32 `protobuf:"varint,4,opt,name=group_size,json=groupSize,proto3" json:"group_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *QuantizationConfig) Reset() {
	*x = QuantizationConfig{}
	mi := &file_model_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *QuantizationConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*QuantizationConfig) ProtoMessage() {}

func (x *QuantizationConfig) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use QuantizationConfig.ProtoReflect.Descriptor instead.
func (*QuantizationConfig) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{3}
}

func (x *QuantizationConfig) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

func (x *QuantizationConfig) GetMethod() string {
	if x != nil {
		return x.Method
	}
	return ""
}

func (x *QuantizationConfig) GetBits() int32 {
	if x != nil {
		return x.Bits
	}
	return 0
}

func (x *QuantizationConfig) GetGroupSize() int32 {
	if x != nil {
		return x.GroupSize
	}
	return 0
}

// TokenizerConfig defines tokenizer settings
type TokenizerConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Tokenizer type (HF, SENTENCEPIECE, TIKTOKEN)
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// Tokenizer path or identifier
	Path string `protobuf:"bytes,2,opt,name=path,proto3" json:"path,omitempty"`
	// Special tokens
	SpecialTokens map[string]string `protobuf:"bytes,3,rep,name=special_tokens,json=specialTokens,proto3" json:"special_tokens,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TokenizerConfig) Reset() {
	*x = TokenizerConfig{}
	mi := &file_model_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TokenizerConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TokenizerConfig) ProtoMessage() {}

func (x *TokenizerConfig) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TokenizerConfig.ProtoReflect.Descriptor instead.
func (*TokenizerConfig) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{4}
}

func (x *TokenizerConfig) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *TokenizerConfig) GetPath() string {
	if x != nil {
		return x.Path
	}
	return ""
}

func (x *TokenizerConfig) GetSpecialTokens() map[string]string {
	if x != nil {
		return x.SpecialTokens
	}
	return nil
}

// ModelCapabilities defines what the model can do
type ModelCapabilities struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Supports streaming responses
	SupportsStreaming bool `protobuf:"varint,1,opt,name=supports_streaming,json=supportsStreaming,proto3" json:"supports_streaming,omitempty"`
	// Supports function calling
	SupportsFunctionCalling bool `protobuf:"varint,2,opt,name=supports_function_calling,json=supportsFunctionCalling,proto3" json:"supports_function_calling,omitempty"`
	// Supports vision inputs
	SupportsVision bool `protobuf:"varint,3,opt,name=supports_vision,json=supportsVision,proto3" json:"supports_vision,omitempty"`
	// Supports audio inputs
	SupportsAudio bool `protobuf:"varint,4,opt,name=supports_audio,json=supportsAudio,proto3" json:"supports_audio,omitempty"`
	// Maximum context window
	MaxContextWindow int32 `protobuf:"varint,5,opt,name=max_context_window,json=maxContextWindow,proto3" json:"max_context_window,omitempty"`
	// Supported languages (ISO 639-1 codes)
	SupportedLanguages []string `protobuf:"bytes,6,rep,name=supported_languages,json=supportedLanguages,proto3" json:"supported_languages,omitempty"`
	// Supported tasks
	SupportedTasks []string `protobuf:"bytes,7,rep,name=supported_tasks,json=supportedTasks,proto3" json:"supported_tasks,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ModelCapabilities) Reset() {
	*x = ModelCapabilities{}
	mi := &file_model_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelCapabilities) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelCapabilities) ProtoMessage() {}

func (x *ModelCapabilities) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelCapabilities.ProtoReflect.Descriptor instead.
func (*ModelCapabilities) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{5}
}

func (x *ModelCapabilities) GetSupportsStreaming() bool {
	if x != nil {
		return x.SupportsStreaming
	}
	return false
}

func (x *ModelCapabilities) GetSupportsFunctionCalling() bool {
	if x != nil {
		return x.SupportsFunctionCalling
	}
	return false
}

func (x *ModelCapabilities) GetSupportsVision() bool {
	if x != nil {
		return x.SupportsVision
	}
	return false
}

func (x *ModelCapabilities) GetSupportsAudio() bool {
	if x != nil {
		return x.SupportsAudio
	}
	return false
}

func (x *ModelCapabilities) GetMaxContextWindow() int32 {
	if x != nil {
		return x.MaxContextWindow
	}
	return 0
}

func (x *ModelCapabilities) GetSupportedLanguages() []string {
	if x != nil {
		return x.SupportedLanguages
	}
	return nil
}

func (x *ModelCapabilities) GetSupportedTasks() []string {
	if x != nil {
		return x.SupportedTasks
	}
	return nil
}

// ResourceRequirements defines resource requirements
type ResourceRequirements struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Minimum GPU memory (in GB)
	MinGpuMemory float32 `protobuf:"fixed32,1,opt,name=min_gpu_memory,json=minGpuMemory,proto3" json:"min_gpu_memory,omitempty"`
	// Number of GPUs required
	NumGpus int32 `protobuf:"varint,2,opt,name=num_gpus,json=numGpus,proto3" json:"num_gpus,omitempty"`
	// Minimum CPU cores
	MinCpuCores int32 `protobuf:"varint,3,opt,name=min_cpu_cores,json=minCpuCores,proto3" json:"min_cpu_cores,omitempty"`
	// Minimum RAM (in GB)
	MinRam float32 `protobuf:"fixed32,4,opt,name=min_ram,json=minRam,proto3" json:"min_ram,omitempty"`
	// Disk space required (in GB)
	DiskSpace float32 `protobuf:"fixed32,5,opt,name=disk_space,json=diskSpace,proto3" json:"disk_space,omitempty"`
	// GPU type requirement (optional)
	GpuType       string `protobuf:"bytes,6,opt,name=gpu_type,json=gpuType,proto3" json:"gpu_type,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResourceRequirements) Reset() {
	*x = ResourceRequirements{}
	mi := &file_model_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResourceRequirements) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResourceRequirements) ProtoMessage() {}

func (x *ResourceRequirements) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResourceRequirements.ProtoReflect.Descriptor instead.
func (*ResourceRequirements) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{6}
}

func (x *ResourceRequirements) GetMinGpuMemory() float32 {
	if x != nil {
		return x.MinGpuMemory
	}
	return 0
}

func (x *ResourceRequirements) GetNumGpus() int32 {
	if x != nil {
		return x.NumGpus
	}
	return 0
}

func (x *ResourceRequirements) GetMinCpuCores() int32 {
	if x != nil {
		return x.MinCpuCores
	}
	return 0
}

func (x *ResourceRequirements) GetMinRam() float32 {
	if x != nil {
		return x.MinRam
	}
	return 0
}

func (x *ResourceRequirements) GetDiskSpace() float32 {
	if x != nil {
		return x.DiskSpace
	}
	return 0
}

func (x *ResourceRequirements) GetGpuType() string {
	if x != nil {
		return x.GpuType
	}
	return ""
}

// RegisterModelRequest is the request for registering a model
type RegisterModelRequest struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	Name             string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Type             ModelType              `protobuf:"varint,2,opt,name=type,proto3,enum=openeeap.model.v1.ModelType" json:"type,omitempty"`
	Version          string                 `protobuf:"bytes,3,opt,name=version,proto3" json:"version,omitempty"`
	Description      string                 `protobuf:"bytes,4,opt,name=description,proto3" json:"description,omitempty"`
	Config           *ModelConfig           `protobuf:"bytes,5,opt,name=config,proto3" json:"config,omitempty"`
	Capabilities     *ModelCapabilities     `protobuf:"bytes,6,opt,name=capabilities,proto3" json:"capabilities,omitempty"`
	Resources        *ResourceRequirements  `protobuf:"bytes,7,opt,name=resources,proto3" json:"resources,omitempty"`
	Provider         string                 `protobuf:"bytes,8,opt,name=provider,proto3" json:"provider,omitempty"`
	CostPer_1KTokens float64                `protobuf:"fixed64,9,opt,name=cost_per_1k_tokens,json=costPer1kTokens,proto3" json:"cost_per_1k_tokens,omitempty"`
	Metadata         map[string]string      `protobuf:"bytes,10,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *RegisterModelRequest) Reset() {
	*x = RegisterModelRequest{}
	mi := &file_model_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RegisterModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RegisterModelRequest) ProtoMessage() {}

func (x *RegisterModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RegisterModelRequest.ProtoReflect.Descriptor instead.
func (*RegisterModelRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{7}
}

func (x *RegisterModelRequest) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *RegisterModelRequest) GetType() ModelType {
	if x != nil {
		return x.Type
	}
	return ModelType_MODEL_TYPE_UNSPECIFIED
}

func (x *RegisterModelRequest) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *RegisterModelRequest) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *RegisterModelRequest) GetConfig() *ModelConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *RegisterModelRequest) GetCapabilities() *ModelCapabilities {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

func (x *RegisterModelRequest) GetResources() *ResourceRequirements {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *RegisterModelRequest) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *RegisterModelRequest) GetCostPer_1KTokens() float64 {
	if x != nil {
		return x.CostPer_1KTokens
	}
	return 0
}

func (x *RegisterModelRequest) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// RegisterModelResponse is the response for registering a model
type RegisterModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         *Model                 `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RegisterModelResponse) Reset() {
	*x = RegisterModelResponse{}
	mi := &file_model_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RegisterModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RegisterModelResponse) ProtoMessage() {}

func (x *RegisterModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RegisterModelResponse.ProtoReflect.Descriptor instead.
func (*RegisterModelResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{8}
}

func (x *RegisterModelResponse) GetModel() *Model {
	if x != nil {
		return x.Model
	}
	return nil
}

// GetModelRequest is the request for getting a model
type GetModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelRequest) Reset() {
	*x = GetModelRequest{}
	mi := &file_model_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelRequest) ProtoMessage() {}

func (x *GetModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelRequest.ProtoReflect.Descriptor instead.
func (*GetModelRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{9}
}

func (x *GetModelRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

// GetModelResponse is the response for getting a model
type GetModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         *Model                 `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelResponse) Reset() {
	*x = GetModelResponse{}
	mi := &file_model_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelResponse) ProtoMessage() {}

func (x *GetModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelResponse.ProtoReflect.Descriptor instead.
func (*GetModelResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{10}
}

func (x *GetModelResponse) GetModel() *Model {
	if x != nil {
		return x.Model
	}
	return nil
}

// ListModelsRequest is the request for listing models
type ListModelsRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Filter by model type
	Type ModelType `protobuf:"varint,1,opt,name=type,proto3,enum=openeeap.model.v1.ModelType" json:"type,omitempty"`
	// Filter by deployment status
	Status DeploymentStatus `protobuf:"varint,2,opt,name=status,proto3,enum=openeeap.model.v1.DeploymentStatus" json:"status,omitempty"`
	// Filter by provider
	Provider string `protobuf:"bytes,3,opt,name=provider,proto3" json:"provider,omitempty"`
	// Search query (name or description)
	Query string `protobuf:"bytes,4,opt,name=query,proto3" json:"query,omitempty"`
	// Pagination: page number (1-indexed)
	Page int32 `protobuf:"varint,5,opt,name=page,proto3" json:"page,omitempty"`
	// Pagination: page size
	PageSize int32 `protobuf:"varint,6,opt,name=page_size,json=pageSize,proto3" json:"page_size,omitempty"`
	// Sort by field (created_at, name, cost_per_1k_tokens)
	SortBy string `protobuf:"bytes,7,opt,name=sort_by,json=sortBy,proto3" json:"sort_by,omitempty"`
	// Sort order (asc, desc)
	SortOrder     string `protobuf:"bytes,8,opt,name=sort_order,json=sortOrder,proto3" json:"sort_order,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsRequest) Reset() {
	*x = ListModelsRequest{}
	mi := &file_model_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsRequest) ProtoMessage() {}

func (x *ListModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsRequest.ProtoReflect.Descriptor instead.
func (*ListModelsRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{11}
}

func (x *ListModelsRequest) GetType() ModelType {
	if x != nil {
		return x.Type
	}
	return ModelType_MODEL_TYPE_UNSPECIFIED
}

func (x *ListModelsRequest) GetStatus() DeploymentStatus {
	if x != nil {
		return x.Status
	}
	return DeploymentStatus_DEPLOYMENT_STATUS_UNSPECIFIED
}

func (x *ListModelsRequest) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *ListModelsRequest) GetQuery() string {
	if x != nil {
		return x.Query
	}
	return ""
}

func (x *ListModelsRequest) GetPage() int32 {
	if x != nil {
		return x.Page
	}
	return 0
}

func (x *ListModelsRequest) GetPageSize() int32 {
	if x != nil {
		return x.PageSize
	}
	return 0
}

func (x *ListModelsRequest) GetSortBy() string {
	if x != nil {
		return x.SortBy
	}
	return ""
}

func (x *ListModelsRequest) GetSortOrder() string {
	if x != nil {
		return x.SortOrder
	}
	return ""
}

// ListModelsResponse is the response for listing models
type ListModelsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Models        []*Model               `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"`
	TotalCount    int32                  `protobuf:"varint,2,opt,name=total_count,json=totalCount,proto3" json:"total_count,omitempty"`
	Page          int32                  `protobuf:"varint,3,opt,name=page,proto3" json:"page,omitempty"`
	PageSize      int32                  `protobuf:"varint,4,opt,name=page_size,json=pageSize,proto3" json:"page_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsResponse) Reset() {
	*x = ListModelsResponse{}
	mi := &file_model_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsResponse) ProtoMessage() {}

func (x *ListModelsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsResponse.ProtoReflect.Descriptor instead.
func (*ListModelsResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{12}
}

func (x *ListModelsResponse) GetModels() []*Model {
	if x != nil {
		return x.Models
	}
	return nil
}

func (x *ListModelsResponse) GetTotalCount() int32 {
	if x != nil {
		return x.TotalCount
	}
	return 0
}

func (x *ListModelsResponse) GetPage() int32 {
	if x != nil {
		return x.Page
	}
	return 0
}

func (x *ListModelsResponse) GetPageSize() int32 {
	if x != nil {
		return x.PageSize
	}
	return 0
}

// UpdateModelRequest is the request for updating a model
type UpdateModelRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Id    string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Fields to update (partial update)
	Name             *string           `protobuf:"bytes,2,opt,name=name,proto3,oneof" json:"name,omitempty"`
	Description      *string           `protobuf:"bytes,3,opt,name=description,proto3,oneof" json:"description,omitempty"`
	Config           *ModelConfig      `protobuf:"bytes,4,opt,name=config,proto3,oneof" json:"config,omitempty"`
	CostPer_1KTokens *float64          `protobuf:"fixed64,5,opt,name=cost_per_1k_tokens,json=costPer1kTokens,proto3,oneof" json:"cost_per_1k_tokens,omitempty"`
	Metadata         map[string]string `protobuf:"bytes,6,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *UpdateModelRequest) Reset() {
	*x = UpdateModelRequest{}
	mi := &file_model_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateModelRequest) ProtoMessage() {}

func (x *UpdateModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateModelRequest.ProtoReflect.Descriptor instead.
func (*UpdateModelRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{13}
}

func (x *UpdateModelRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *UpdateModelRequest) GetName() string {
	if x != nil && x.Name != nil {
		return *x.Name
	}
	return ""
}

func (x *UpdateModelRequest) GetDescription() string {
	if x != nil && x.Description != nil {
		return *x.Description
	}
	return ""
}

func (x *UpdateModelRequest) GetConfig() *ModelConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *UpdateModelRequest) GetCostPer_1KTokens() float64 {
	if x != nil && x.CostPer_1KTokens != nil {
		return *x.CostPer_1KTokens
	}
	return 0
}

func (x *UpdateModelRequest) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// UpdateModelResponse is the response for updating a model
type UpdateModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         *Model                 `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpdateModelResponse) Reset() {
	*x = UpdateModelResponse{}
	mi := &file_model_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateModelResponse) ProtoMessage() {}

func (x *UpdateModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateModelResponse.ProtoReflect.Descriptor instead.
func (*UpdateModelResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{14}
}

func (x *UpdateModelResponse) GetModel() *Model {
	if x != nil {
		return x.Model
	}
	return nil
}

// DeleteModelRequest is the request for deleting a model
type DeleteModelRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Id    string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Force delete even if deployed
	Force         bool `protobuf:"varint,2,opt,name=force,proto3" json:"force,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteModelRequest) Reset() {
	*x = DeleteModelRequest{}
	mi := &file_model_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteModelRequest) ProtoMessage() {}

func (x *DeleteModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteModelRequest.ProtoReflect.Descriptor instead.
func (*DeleteModelRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{15}
}

func (x *DeleteModelRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *DeleteModelRequest) GetForce() bool {
	if x != nil {
		return x.Force
	}
	return false
}

// DeleteModelResponse is the response for deleting a model
type DeleteModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Message       string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteModelResponse) Reset() {
	*x = DeleteModelResponse{}
	mi := &file_model_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteModelResponse) ProtoMessage() {}

func (x *DeleteModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteModelResponse.ProtoReflect.Descriptor instead.
func (*DeleteModelResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{16}
}

func (x *DeleteModelResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *DeleteModelResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

// DeployModelRequest is the request for deploying a model
type DeployModelRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Id    string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Deployment configuration
	DeploymentConfig *DeploymentConfig `protobuf:"bytes,2,opt,name=deployment_config,json=deploymentConfig,proto3" json:"deployment_config,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *DeployModelRequest) Reset() {
	*x = DeployModelRequest{}
	mi := &file_model_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeployModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeployModelRequest) ProtoMessage() {}

func (x *DeployModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeployModelRequest.ProtoReflect.Descriptor instead.
func (*DeployModelRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{17}
}

func (x *DeployModelRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *DeployModelRequest) GetDeploymentConfig() *DeploymentConfig {
	if x != nil {
		return x.DeploymentConfig
	}
	return nil
}

// DeploymentConfig defines deployment-specific configuration
type DeploymentConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Number of replicas
	Replicas int32 `protobuf:"varint,1,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// Resource allocation (overrides model defaults)
	ResourceAllocation *ResourceAllocation `protobuf:"bytes,2,opt,name=resource_allocation,json=resourceAllocation,proto3" json:"resource_allocation,omitempty"`
	// Auto-scaling configuration
	AutoScaling *AutoScalingConfig `protobuf:"bytes,3,opt,name=auto_scaling,json=autoScaling,proto3" json:"auto_scaling,omitempty"`
	// Health check configuration
	HealthCheck *HealthCheckConfig `protobuf:"bytes,4,opt,name=health_check,json=healthCheck,proto3" json:"health_check,omitempty"`
	// Deployment namespace (for K8s)
	Namespace     string `protobuf:"bytes,5,opt,name=namespace,proto3" json:"namespace,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeploymentConfig) Reset() {
	*x = DeploymentConfig{}
	mi := &file_model_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeploymentConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeploymentConfig) ProtoMessage() {}

func (x *DeploymentConfig) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeploymentConfig.ProtoReflect.Descriptor instead.
func (*DeploymentConfig) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{18}
}

func (x *DeploymentConfig) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *DeploymentConfig) GetResourceAllocation() *ResourceAllocation {
	if x != nil {
		return x.ResourceAllocation
	}
	return nil
}

func (x *DeploymentConfig) GetAutoScaling() *AutoScalingConfig {
	if x != nil {
		return x.AutoScaling
	}
	return nil
}

func (x *DeploymentConfig) GetHealthCheck() *HealthCheckConfig {
	if x != nil {
		return x.HealthCheck
	}
	return nil
}

func (x *DeploymentConfig) GetNamespace() string {
	if x != nil {
		return x.Namespace
	}
	return ""
}

// ResourceAllocation defines actual resource allocation
type ResourceAllocation struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	GpuCount      int32                  `protobuf:"varint,1,opt,name=gpu_count,json=gpuCount,proto3" json:"gpu_count,omitempty"`
	GpuType       string                 `protobuf:"bytes,2,opt,name=gpu_type,json=gpuType,proto3" json:"gpu_type,omitempty"`
	CpuCores      int32                  `protobuf:"varint,3,opt,name=cpu_cores,json=cpuCores,proto3" json:"cpu_cores,omitempty"`
	MemoryGb      float32                `protobuf:"fixed32,4,opt,name=memory_gb,json=memoryGb,proto3" json:"memory_gb,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResourceAllocation) Reset() {
	*x = ResourceAllocation{}
	mi := &file_model_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResourceAllocation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResourceAllocation) ProtoMessage() {}

func (x *ResourceAllocation) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResourceAllocation.ProtoReflect.Descriptor instead.
func (*ResourceAllocation) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{19}
}

func (x *ResourceAllocation) GetGpuCount() int32 {
	if x != nil {
		return x.GpuCount
	}
	return 0
}

func (x *ResourceAllocation) GetGpuType() string {
	if x != nil {
		return x.GpuType
	}
	return ""
}

func (x *ResourceAllocation) GetCpuCores() int32 {
	if x != nil {
		return x.CpuCores
	}
	return 0
}

func (x *ResourceAllocation) GetMemoryGb() float32 {
	if x != nil {
		return x.MemoryGb
	}
	return 0
}

// AutoScalingConfig defines auto-scaling rules
type AutoScalingConfig struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	Enabled              bool                   `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
	MinReplicas          int32                  `protobuf:"varint,2,opt,name=min_replicas,json=minReplicas,proto3" json:"min_replicas,omitempty"`
	MaxReplicas          int32                  `protobuf:"varint,3,opt,name=max_replicas,json=maxReplicas,proto3" json:"max_replicas,omitempty"`
	TargetCpuUtilization int32                  `protobuf:"varint,4,opt,name=target_cpu_utilization,json=targetCpuUtilization,proto3" json:"target_cpu_utilization,omitempty"`
	TargetQps            int32                  `protobuf:"varint,5,opt,name=target_qps,json=targetQps,proto3" json:"target_qps,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *AutoScalingConfig) Reset() {
	*x = AutoScalingConfig{}
	mi := &file_model_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AutoScalingConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AutoScalingConfig) ProtoMessage() {}

func (x *AutoScalingConfig) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AutoScalingConfig.ProtoReflect.Descriptor instead.
func (*AutoScalingConfig) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{20}
}

func (x *AutoScalingConfig) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

func (x *AutoScalingConfig) GetMinReplicas() int32 {
	if x != nil {
		return x.MinReplicas
	}
	return 0
}

func (x *AutoScalingConfig) GetMaxReplicas() int32 {
	if x != nil {
		return x.MaxReplicas
	}
	return 0
}

func (x *AutoScalingConfig) GetTargetCpuUtilization() int32 {
	if x != nil {
		return x.TargetCpuUtilization
	}
	return 0
}

func (x *AutoScalingConfig) GetTargetQps() int32 {
	if x != nil {
		return x.TargetQps
	}
	return 0
}

// HealthCheckConfig defines health check settings
type HealthCheckConfig struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	InitialDelaySeconds int32                  `protobuf:"varint,1,opt,name=initial_delay_seconds,json=initialDelaySeconds,proto3" json:"initial_delay_seconds,omitempty"`
	PeriodSeconds       int32                  `protobuf:"varint,2,opt,name=period_seconds,json=periodSeconds,proto3" json:"period_seconds,omitempty"`
	TimeoutSeconds      int32                  `protobuf:"varint,3,opt,name=timeout_seconds,json=timeoutSeconds,proto3" json:"timeout_seconds,omitempty"`
	FailureThreshold    int32                  `protobuf:"varint,4,opt,name=failure_threshold,json=failureThreshold,proto3" json:"failure_threshold,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *HealthCheckConfig) Reset() {
	*x = HealthCheckConfig{}
	mi := &file_model_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckConfig) ProtoMessage() {}

func (x *HealthCheckConfig) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckConfig.ProtoReflect.Descriptor instead.
func (*HealthCheckConfig) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{21}
}

func (x *HealthCheckConfig) GetInitialDelaySeconds() int32 {
	if x != nil {
		return x.InitialDelaySeconds
	}
	return 0
}

func (x *HealthCheckConfig) GetPeriodSeconds() int32 {
	if x != nil {
		return x.PeriodSeconds
	}
	return 0
}

func (x *HealthCheckConfig) GetTimeoutSeconds() int32 {
	if x != nil {
		return x.TimeoutSeconds
	}
	return 0
}

func (x *HealthCheckConfig) GetFailureThreshold() int32 {
	if x != nil {
		return x.FailureThreshold
	}
	return 0
}

// DeployModelResponse is the response for deploying a model
type DeployModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         *Model                 `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	DeploymentId  string                 `protobuf:"bytes,2,opt,name=deployment_id,json=deploymentId,proto3" json:"deployment_id,omitempty"`
	Message       string                 `protobuf:"bytes,3,opt,name=message,proto3" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeployModelResponse) Reset() {
	*x = DeployModelResponse{}
	mi := &file_model_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeployModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeployModelResponse) ProtoMessage() {}

func (x *DeployModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeployModelResponse.ProtoReflect.Descriptor instead.
func (*DeployModelResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{22}
}

func (x *DeployModelResponse) GetModel() *Model {
	if x != nil {
		return x.Model
	}
	return nil
}

func (x *DeployModelResponse) GetDeploymentId() string {
	if x != nil {
		return x.DeploymentId
	}
	return ""
}

func (x *DeployModelResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

// UndeployModelRequest is the request for undeploying a model
type UndeployModelRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Id    string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Graceful shutdown timeout (seconds)
	TimeoutSeconds int32 `protobuf:"varint,2,opt,name=timeout_seconds,json=timeoutSeconds,proto3" json:"timeout_seconds,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *UndeployModelRequest) Reset() {
	*x = UndeployModelRequest{}
	mi := &file_model_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UndeployModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UndeployModelRequest) ProtoMessage() {}

func (x *UndeployModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UndeployModelRequest.ProtoReflect.Descriptor instead.
func (*UndeployModelRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{23}
}

func (x *UndeployModelRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *UndeployModelRequest) GetTimeoutSeconds() int32 {
	if x != nil {
		return x.TimeoutSeconds
	}
	return 0
}

// UndeployModelResponse is the response for undeploying a model
type UndeployModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Message       string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UndeployModelResponse) Reset() {
	*x = UndeployModelResponse{}
	mi := &file_model_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UndeployModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UndeployModelResponse) ProtoMessage() {}

func (x *UndeployModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UndeployModelResponse.ProtoReflect.Descriptor instead.
func (*UndeployModelResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{24}
}

func (x *UndeployModelResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *UndeployModelResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

// GetModelMetricsRequest is the request for getting model metrics
type GetModelMetricsRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Id    string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Time range for metrics
	StartTime *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	EndTime   *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`
	// Metrics to retrieve
	MetricNames   []string `protobuf:"bytes,4,rep,name=metric_names,json=metricNames,proto3" json:"metric_names,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelMetricsRequest) Reset() {
	*x = GetModelMetricsRequest{}
	mi := &file_model_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelMetricsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelMetricsRequest) ProtoMessage() {}

func (x *GetModelMetricsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelMetricsRequest.ProtoReflect.Descriptor instead.
func (*GetModelMetricsRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{25}
}

func (x *GetModelMetricsRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *GetModelMetricsRequest) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *GetModelMetricsRequest) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *GetModelMetricsRequest) GetMetricNames() []string {
	if x != nil {
		return x.MetricNames
	}
	return nil
}

// GetModelMetricsResponse is the response for getting model metrics
type GetModelMetricsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Metrics       *ModelMetrics          `protobuf:"bytes,1,opt,name=metrics,proto3" json:"metrics,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelMetricsResponse) Reset() {
	*x = GetModelMetricsResponse{}
	mi := &file_model_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelMetricsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelMetricsResponse) ProtoMessage() {}

func (x *GetModelMetricsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelMetricsResponse.ProtoReflect.Descriptor instead.
func (*GetModelMetricsResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{26}
}

func (x *GetModelMetricsResponse) GetMetrics() *ModelMetrics {
	if x != nil {
		return x.Metrics
	}
	return nil
}

// ModelMetrics contains model performance metrics
type ModelMetrics struct {
	state     protoimpl.MessageState `protogen:"open.v1"`
	ModelId   string                 `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	Timestamp *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=timestamp,proto3" json:"timestamp,omitempty"`
	// Throughput metrics
	Qps             float64 `protobuf:"fixed64,3,opt,name=qps,proto3" json:"qps,omitempty"`                                                  // Queries per second
	TokensPerSecond float64 `protobuf:"fixed64,4,opt,name=tokens_per_second,json=tokensPerSecond,proto3" json:"tokens_per_second,omitempty"` // Tokens generated per second
	// Latency metrics (in milliseconds)
	AvgLatency float64 `protobuf:"fixed64,5,opt,name=avg_latency,json=avgLatency,proto3" json:"avg_latency,omitempty"`
	P50Latency float64 `protobuf:"fixed64,6,opt,name=p50_latency,json=p50Latency,proto3" json:"p50_latency,omitempty"`
	P95Latency float64 `protobuf:"fixed64,7,opt,name=p95_latency,json=p95Latency,proto3" json:"p95_latency,omitempty"`
	P99Latency float64 `protobuf:"fixed64,8,opt,name=p99_latency,json=p99Latency,proto3" json:"p99_latency,omitempty"`
	// Resource utilization
	GpuUtilization       float32 `protobuf:"fixed32,9,opt,name=gpu_utilization,json=gpuUtilization,proto3" json:"gpu_utilization,omitempty"`                      // 0.0 - 1.0
	GpuMemoryUtilization float32 `protobuf:"fixed32,10,opt,name=gpu_memory_utilization,json=gpuMemoryUtilization,proto3" json:"gpu_memory_utilization,omitempty"` // 0.0 - 1.0
	CpuUtilization       float32 `protobuf:"fixed32,11,opt,name=cpu_utilization,json=cpuUtilization,proto3" json:"cpu_utilization,omitempty"`                     // 0.0 - 1.0
	MemoryUtilization    float32 `protobuf:"fixed32,12,opt,name=memory_utilization,json=memoryUtilization,proto3" json:"memory_utilization,omitempty"`            // 0.0 - 1.0
	// Cache metrics
	CacheHitRate float64 `protobuf:"fixed64,13,opt,name=cache_hit_rate,json=cacheHitRate,proto3" json:"cache_hit_rate,omitempty"` // 0.0 - 1.0
	// Error metrics
	ErrorRate      float64 `protobuf:"fixed64,14,opt,name=error_rate,json=errorRate,proto3" json:"error_rate,omitempty"` // 0.0 - 1.0
	TotalRequests  int64   `protobuf:"varint,15,opt,name=total_requests,json=totalRequests,proto3" json:"total_requests,omitempty"`
	FailedRequests int64   `protobuf:"varint,16,opt,name=failed_requests,json=failedRequests,proto3" json:"failed_requests,omitempty"`
	// Cost metrics
	TotalCost      float64 `protobuf:"fixed64,17,opt,name=total_cost,json=totalCost,proto3" json:"total_cost,omitempty"` // In USD
	CostPerRequest float64 `protobuf:"fixed64,18,opt,name=cost_per_request,json=costPerRequest,proto3" json:"cost_per_request,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ModelMetrics) Reset() {
	*x = ModelMetrics{}
	mi := &file_model_proto_msgTypes[27]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelMetrics) ProtoMessage() {}

func (x *ModelMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[27]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelMetrics.ProtoReflect.Descriptor instead.
func (*ModelMetrics) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{27}
}

func (x *ModelMetrics) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *ModelMetrics) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

func (x *ModelMetrics) GetQps() float64 {
	if x != nil {
		return x.Qps
	}
	return 0
}

func (x *ModelMetrics) GetTokensPerSecond() float64 {
	if x != nil {
		return x.TokensPerSecond
	}
	return 0
}

func (x *ModelMetrics) GetAvgLatency() float64 {
	if x != nil {
		return x.AvgLatency
	}
	return 0
}

func (x *ModelMetrics) GetP50Latency() float64 {
	if x != nil {
		return x.P50Latency
	}
	return 0
}

func (x *ModelMetrics) GetP95Latency() float64 {
	if x != nil {
		return x.P95Latency
	}
	return 0
}

func (x *ModelMetrics) GetP99Latency() float64 {
	if x != nil {
		return x.P99Latency
	}
	return 0
}

func (x *ModelMetrics) GetGpuUtilization() float32 {
	if x != nil {
		return x.GpuUtilization
	}
	return 0
}

func (x *ModelMetrics) GetGpuMemoryUtilization() float32 {
	if x != nil {
		return x.GpuMemoryUtilization
	}
	return 0
}

func (x *ModelMetrics) GetCpuUtilization() float32 {
	if x != nil {
		return x.CpuUtilization
	}
	return 0
}

func (x *ModelMetrics) GetMemoryUtilization() float32 {
	if x != nil {
		return x.MemoryUtilization
	}
	return 0
}

func (x *ModelMetrics) GetCacheHitRate() float64 {
	if x != nil {
		return x.CacheHitRate
	}
	return 0
}

func (x *ModelMetrics) GetErrorRate() float64 {
	if x != nil {
		return x.ErrorRate
	}
	return 0
}

func (x *ModelMetrics) GetTotalRequests() int64 {
	if x != nil {
		return x.TotalRequests
	}
	return 0
}

func (x *ModelMetrics) GetFailedRequests() int64 {
	if x != nil {
		return x.FailedRequests
	}
	return 0
}

func (x *ModelMetrics) GetTotalCost() float64 {
	if x != nil {
		return x.TotalCost
	}
	return 0
}

func (x *ModelMetrics) GetCostPerRequest() float64 {
	if x != nil {
		return x.CostPerRequest
	}
	return 0
}

// StreamModelMetricsRequest is the request for streaming metrics
type StreamModelMetricsRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Id    string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Metrics update interval (seconds)
	IntervalSeconds int32 `protobuf:"varint,2,opt,name=interval_seconds,json=intervalSeconds,proto3" json:"interval_seconds,omitempty"`
	// Metrics to stream
	MetricNames   []string `protobuf:"bytes,3,rep,name=metric_names,json=metricNames,proto3" json:"metric_names,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamModelMetricsRequest) Reset() {
	*x = StreamModelMetricsRequest{}
	mi := &file_model_proto_msgTypes[28]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamModelMetricsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamModelMetricsRequest) ProtoMessage() {}

func (x *StreamModelMetricsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[28]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamModelMetricsRequest.ProtoReflect.Descriptor instead.
func (*StreamModelMetricsRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{28}
}

func (x *StreamModelMetricsRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *StreamModelMetricsRequest) GetIntervalSeconds() int32 {
	if x != nil {
		return x.IntervalSeconds
	}
	return 0
}

func (x *StreamModelMetricsRequest) GetMetricNames() []string {
	if x != nil {
		return x.MetricNames
	}
	return nil
}

// ModelMetricsEvent is a single metrics event in the stream
type ModelMetricsEvent struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Metrics       *ModelMetrics          `protobuf:"bytes,1,opt,name=metrics,proto3" json:"metrics,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelMetricsEvent) Reset() {
	*x = ModelMetricsEvent{}
	mi := &file_model_proto_msgTypes[29]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelMetricsEvent) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelMetricsEvent) ProtoMessage() {}

func (x *ModelMetricsEvent) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[29]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelMetricsEvent.ProtoReflect.Descriptor instead.
func (*ModelMetricsEvent) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{29}
}

func (x *ModelMetricsEvent) GetMetrics() *ModelMetrics {
	if x != nil {
		return x.Metrics
	}
	return nil
}

// HealthCheckRequest is the request for health check
type HealthCheckRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckRequest) Reset() {
	*x = HealthCheckRequest{}
	mi := &file_model_proto_msgTypes[30]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckRequest) ProtoMessage() {}

func (x *HealthCheckRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[30]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckRequest.ProtoReflect.Descriptor instead.
func (*HealthCheckRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{30}
}

func (x *HealthCheckRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

// HealthCheckResponse is the response for health check
type HealthCheckResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Healthy       bool                   `protobuf:"varint,1,opt,name=healthy,proto3" json:"healthy,omitempty"`
	Status        string                 `protobuf:"bytes,2,opt,name=status,proto3" json:"status,omitempty"`
	Message       string                 `protobuf:"bytes,3,opt,name=message,proto3" json:"message,omitempty"`
	Details       map[string]string      `protobuf:"bytes,4,rep,name=details,proto3" json:"details,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	LastCheckTime *timestamppb.Timestamp `protobuf:"bytes,5,opt,name=last_check_time,json=lastCheckTime,proto3" json:"last_check_time,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckResponse) Reset() {
	*x = HealthCheckResponse{}
	mi := &file_model_proto_msgTypes[31]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckResponse) ProtoMessage() {}

func (x *HealthCheckResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[31]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckResponse.ProtoReflect.Descriptor instead.
func (*HealthCheckResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{31}
}

func (x *HealthCheckResponse) GetHealthy() bool {
	if x != nil {
		return x.Healthy
	}
	return false
}

func (x *HealthCheckResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *HealthCheckResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *HealthCheckResponse) GetDetails() map[string]string {
	if x != nil {
		return x.Details
	}
	return nil
}

func (x *HealthCheckResponse) GetLastCheckTime() *timestamppb.Timestamp {
	if x != nil {
		return x.LastCheckTime
	}
	return nil
}

// ValidateModelRequest is the request for validating model configuration
type ValidateModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Config        *ModelConfig           `protobuf:"bytes,1,opt,name=config,proto3" json:"config,omitempty"`
	Resources     *ResourceRequirements  `protobuf:"bytes,2,opt,name=resources,proto3" json:"resources,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ValidateModelRequest) Reset() {
	*x = ValidateModelRequest{}
	mi := &file_model_proto_msgTypes[32]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ValidateModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ValidateModelRequest) ProtoMessage() {}

func (x *ValidateModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[32]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ValidateModelRequest.ProtoReflect.Descriptor instead.
func (*ValidateModelRequest) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{32}
}

func (x *ValidateModelRequest) GetConfig() *ModelConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *ValidateModelRequest) GetResources() *ResourceRequirements {
	if x != nil {
		return x.Resources
	}
	return nil
}

// ValidateModelResponse is the response for validating model configuration
type ValidateModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Valid         bool                   `protobuf:"varint,1,opt,name=valid,proto3" json:"valid,omitempty"`
	Errors        []*ValidationError     `protobuf:"bytes,2,rep,name=errors,proto3" json:"errors,omitempty"`
	Warnings      []string               `protobuf:"bytes,3,rep,name=warnings,proto3" json:"warnings,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ValidateModelResponse) Reset() {
	*x = ValidateModelResponse{}
	mi := &file_model_proto_msgTypes[33]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ValidateModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ValidateModelResponse) ProtoMessage() {}

func (x *ValidateModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[33]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ValidateModelResponse.ProtoReflect.Descriptor instead.
func (*ValidateModelResponse) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{33}
}

func (x *ValidateModelResponse) GetValid() bool {
	if x != nil {
		return x.Valid
	}
	return false
}

func (x *ValidateModelResponse) GetErrors() []*ValidationError {
	if x != nil {
		return x.Errors
	}
	return nil
}

func (x *ValidateModelResponse) GetWarnings() []string {
	if x != nil {
		return x.Warnings
	}
	return nil
}

// ValidationError represents a validation error
type ValidationError struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Field         string                 `protobuf:"bytes,1,opt,name=field,proto3" json:"field,omitempty"`
	Message       string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	Code          string                 `protobuf:"bytes,3,opt,name=code,proto3" json:"code,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ValidationError) Reset() {
	*x = ValidationError{}
	mi := &file_model_proto_msgTypes[34]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ValidationError) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ValidationError) ProtoMessage() {}

func (x *ValidationError) ProtoReflect() protoreflect.Message {
	mi := &file_model_proto_msgTypes[34]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ValidationError.ProtoReflect.Descriptor instead.
func (*ValidationError) Descriptor() ([]byte, []int) {
	return file_model_proto_rawDescGZIP(), []int{34}
}

func (x *ValidationError) GetField() string {
	if x != nil {
		return x.Field
	}
	return ""
}

func (x *ValidationError) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *ValidationError) GetCode() string {
	if x != nil {
		return x.Code
	}
	return ""
}

var File_model_proto protoreflect.FileDescriptor

const file_model_proto_rawDesc = "" +
	"\n" +
	"\vmodel.proto\x12\x11openeeap.model.v1\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1cgoogle/protobuf/struct.proto\"\x9a\x06\n" +
	"\x05Model\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x120\n" +
	"\x04type\x18\x03 \x01(\x0e2\x1c.openeeap.model.v1.ModelTypeR\x04type\x12\x18\n" +
	"\aversion\x18\x04 \x01(\tR\aversion\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x126\n" +
	"\x06config\x18\x06 \x01(\v2\x1e.openeeap.model.v1.ModelConfigR\x06config\x12H\n" +
	"\fcapabilities\x18\a \x01(\v2$.openeeap.model.v1.ModelCapabilitiesR\fcapabilities\x12E\n" +
	"\tresources\x18\b \x01(\v2'.openeeap.model.v1.ResourceRequirementsR\tresources\x12;\n" +
	"\x06status\x18\t \x01(\x0e2#.openeeap.model.v1.DeploymentStatusR\x06status\x12\x1a\n" +
	"\bendpoint\x18\n" +
	" \x01(\tR\bendpoint\x12\x1a\n" +
	"\bprovider\x18\v \x01(\tR\bprovider\x12+\n" +
	"\x12cost_per_1k_tokens\x18\f \x01(\x01R\x0fcostPer1kTokens\x12B\n" +
	"\bmetadata\x18\r \x03(\v2&.openeeap.model.v1.Model.MetadataEntryR\bmetadata\x129\n" +
	"\n" +
	"created_at\x18\x0e \x01(\v2\x1a.google.protobuf.TimestampR\tcreatedAt\x129\n" +
	"\n" +
	"updated_at\x18\x0f \x01(\v2\x1a.google.protobuf.TimestampR\tupdatedAt\x12\x1d\n" +
	"\n" +
	"created_by\x18\x10 \x01(\tR\tcreatedBy\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xf1\x02\n" +
	"\vModelConfig\x12\x1d\n" +
	"\n" +
	"model_path\x18\x01 \x01(\tR\tmodelPath\x12)\n" +
	"\x10inference_engine\x18\x02 \x01(\tR\x0finferenceEngine\x12M\n" +
	"\x10inference_config\x18\x03 \x01(\v2\".openeeap.model.v1.InferenceConfigR\x0finferenceConfig\x12I\n" +
	"\fquantization\x18\x04 \x01(\v2%.openeeap.model.v1.QuantizationConfigR\fquantization\x12@\n" +
	"\ttokenizer\x18\x05 \x01(\v2\".openeeap.model.v1.TokenizerConfigR\ttokenizer\x12<\n" +
	"\rcustom_config\x18\x06 \x01(\v2\x17.google.protobuf.StructR\fcustomConfig\"\x9f\x03\n" +
	"\x0fInferenceConfig\x12$\n" +
	"\x0emax_seq_length\x18\x01 \x01(\x05R\fmaxSeqLength\x12\x1d\n" +
	"\n" +
	"batch_size\x18\x02 \x01(\x05R\tbatchSize\x124\n" +
	"\x16gpu_memory_utilization\x18\x03 \x01(\x02R\x14gpuMemoryUtilization\x12&\n" +
	"\x0fenable_kv_cache\x18\x04 \x01(\bR\renableKvCache\x120\n" +
	"\x14tensor_parallel_size\x18\x05 \x01(\x05R\x12tensorParallelSize\x124\n" +
	"\x16pipeline_parallel_size\x18\x06 \x01(\x05R\x14pipelineParallelSize\x12/\n" +
	"\x13default_temperature\x18\a \x01(\x02R\x12defaultTemperature\x12\"\n" +
	"\rdefault_top_p\x18\b \x01(\x02R\vdefaultTopP\x12,\n" +
	"\x12default_max_tokens\x18\t \x01(\x05R\x10defaultMaxTokens\"y\n" +
	"\x12QuantizationConfig\x12\x18\n" +
	"\aenabled\x18\x01 \x01(\bR\aenabled\x12\x16\n" +
	"\x06method\x18\x02 \x01(\tR\x06method\x12\x12\n" +
	"\x04bits\x18\x03 \x01(\x05R\x04bits\x12\x1d\n" +
	"\n" +
	"group_size\x18\x04 \x01(\x05R\tgroupSize\"\xd9\x01\n" +
	"\x0fTokenizerConfig\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x12\x12\n" +
	"\x04path\x18\x02 \x01(\tR\x04path\x12\\\n" +
	"\x0especial_tokens\x18\x03 \x03(\v25.openeeap.model.v1.TokenizerConfig.SpecialTokensEntryR\rspecialTokens\x1a@\n" +
	"\x12SpecialTokensEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xd6\x02\n" +
	"\x11ModelCapabilities\x12-\n" +
	"\x12supports_streaming\x18\x01 \x01(\bR\x11supportsStreaming\x12:\n" +
	"\x19supports_function_calling\x18\x02 \x01(\bR\x17supportsFunctionCalling\x12'\n" +
	"\x0fsupports_vision\x18\x03 \x01(\bR\x0esupportsVision\x12%\n" +
	"\x0esupports_audio\x18\x04 \x01(\bR\rsupportsAudio\x12,\n" +
	"\x12max_context_window\x18\x05 \x01(\x05R\x10maxContextWindow\x12/\n" +
	"\x13supported_languages\x18\x06 \x03(\tR\x12supportedLanguages\x12'\n" +
	"\x0fsupported_tasks\x18\a \x03(\tR\x0esupportedTasks\"\xce\x01\n" +
	"\x14ResourceRequirements\x12$\n" +
	"\x0emin_gpu_memory\x18\x01 \x01(\x02R\fminGpuMemory\x12\x19\n" +
	"\bnum_gpus\x18\x02 \x01(\x05R\anumGpus\x12\"\n" +
	"\rmin_cpu_cores\x18\x03 \x01(\x05R\vminCpuCores\x12\x17\n" +
	"\amin_ram\x18\x04 \x01(\x02R\x06minRam\x12\x1d\n" +
	"\n" +
	"disk_space\x18\x05 \x01(\x02R\tdiskSpace\x12\x19\n" +
	"\bgpu_type\x18\x06 \x01(\tR\agpuType\"\xba\x04\n" +
	"\x14RegisterModelRequest\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x120\n" +
	"\x04type\x18\x02 \x01(\x0e2\x1c.openeeap.model.v1.ModelTypeR\x04type\x12\x18\n" +
	"\aversion\x18\x03 \x01(\tR\aversion\x12 \n" +
	"\vdescription\x18\x04 \x01(\tR\vdescription\x126\n" +
	"\x06config\x18\x05 \x01(\v2\x1e.openeeap.model.v1.ModelConfigR\x06config\x12H\n" +
	"\fcapabilities\x18\x06 \x01(\v2$.openeeap.model.v1.ModelCapabilitiesR\fcapabilities\x12E\n" +
	"\tresources\x18\a \x01(\v2'.openeeap.model.v1.ResourceRequirementsR\tresources\x12\x1a\n" +
	"\bprovider\x18\b \x01(\tR\bprovider\x12+\n" +
	"\x12cost_per_1k_tokens\x18\t \x01(\x01R\x0fcostPer1kTokens\x12Q\n" +
	"\bmetadata\x18\n" +
	" \x03(\v25.openeeap.model.v1.RegisterModelRequest.MetadataEntryR\bmetadata\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"G\n" +
	"\x15RegisterModelResponse\x12.\n" +
	"\x05model\x18\x01 \x01(\v2\x18.openeeap.model.v1.ModelR\x05model\"!\n" +
	"\x0fGetModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\"B\n" +
	"\x10GetModelResponse\x12.\n" +
	"\x05model\x18\x01 \x01(\v2\x18.openeeap.model.v1.ModelR\x05model\"\x9d\x02\n" +
	"\x11ListModelsRequest\x120\n" +
	"\x04type\x18\x01 \x01(\x0e2\x1c.openeeap.model.v1.ModelTypeR\x04type\x12;\n" +
	"\x06status\x18\x02 \x01(\x0e2#.openeeap.model.v1.DeploymentStatusR\x06status\x12\x1a\n" +
	"\bprovider\x18\x03 \x01(\tR\bprovider\x12\x14\n" +
	"\x05query\x18\x04 \x01(\tR\x05query\x12\x12\n" +
	"\x04page\x18\x05 \x01(\x05R\x04page\x12\x1b\n" +
	"\tpage_size\x18\x06 \x01(\x05R\bpageSize\x12\x17\n" +
	"\asort_by\x18\a \x01(\tR\x06sortBy\x12\x1d\n" +
	"\n" +
	"sort_order\x18\b \x01(\tR\tsortOrder\"\x98\x01\n" +
	"\x12ListModelsResponse\x120\n" +
	"\x06models\x18\x01 \x03(\v2\x18.openeeap.model.v1.ModelR\x06models\x12\x1f\n" +
	"\vtotal_count\x18\x02 \x01(\x05R\n" +
	"totalCount\x12\x12\n" +
	"\x04page\x18\x03 \x01(\x05R\x04page\x12\x1b\n" +
	"\tpage_size\x18\x04 \x01(\x05R\bpageSize\"\x9c\x03\n" +
	"\x12UpdateModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x17\n" +
	"\x04name\x18\x02 \x01(\tH\x00R\x04name\x88\x01\x01\x12%\n" +
	"\vdescription\x18\x03 \x01(\tH\x01R\vdescription\x88\x01\x01\x12;\n" +
	"\x06config\x18\x04 \x01(\v2\x1e.openeeap.model.v1.ModelConfigH\x02R\x06config\x88\x01\x01\x120\n" +
	"\x12cost_per_1k_tokens\x18\x05 \x01(\x01H\x03R\x0fcostPer1kTokens\x88\x01\x01\x12O\n" +
	"\bmetadata\x18\x06 \x03(\v23.openeeap.model.v1.UpdateModelRequest.MetadataEntryR\bmetadata\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01B\a\n" +
	"\x05_nameB\x0e\n" +
	"\f_descriptionB\t\n" +
	"\a_configB\x15\n" +
	"\x13_cost_per_1k_tokens\"E\n" +
	"\x13UpdateModelResponse\x12.\n" +
	"\x05model\x18\x01 \x01(\v2\x18.openeeap.model.v1.ModelR\x05model\":\n" +
	"\x12DeleteModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x14\n" +
	"\x05force\x18\x02 \x01(\bR\x05force\"I\n" +
	"\x13DeleteModelResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\"v\n" +
	"\x12DeployModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12P\n" +
	"\x11deployment_config\x18\x02 \x01(\v2#.openeeap.model.v1.DeploymentConfigR\x10deploymentConfig\"\xb6\x02\n" +
	"\x10DeploymentConfig\x12\x1a\n" +
	"\breplicas\x18\x01 \x01(\x05R\breplicas\x12V\n" +
	"\x13resource_allocation\x18\x02 \x01(\v2%.openeeap.model.v1.ResourceAllocationR\x12resourceAllocation\x12G\n" +
	"\fauto_scaling\x18\x03 \x01(\v2$.openeeap.model.v1.AutoScalingConfigR\vautoScaling\x12G\n" +
	"\fhealth_check\x18\x04 \x01(\v2$.openeeap.model.v1.HealthCheckConfigR\vhealthCheck\x12\x1c\n" +
	"\tnamespace\x18\x05 \x01(\tR\tnamespace\"\x86\x01\n" +
	"\x12ResourceAllocation\x12\x1b\n" +
	"\tgpu_count\x18\x01 \x01(\x05R\bgpuCount\x12\x19\n" +
	"\bgpu_type\x18\x02 \x01(\tR\agpuType\x12\x1b\n" +
	"\tcpu_cores\x18\x03 \x01(\x05R\bcpuCores\x12\x1b\n" +
	"\tmemory_gb\x18\x04 \x01(\x02R\bmemoryGb\"\xc8\x01\n" +
	"\x11AutoScalingConfig\x12\x18\n" +
	"\aenabled\x18\x01 \x01(\bR\aenabled\x12!\n" +
	"\fmin_replicas\x18\x02 \x01(\x05R\vminReplicas\x12!\n" +
	"\fmax_replicas\x18\x03 \x01(\x05R\vmaxReplicas\x124\n" +
	"\x16target_cpu_utilization\x18\x04 \x01(\x05R\x14targetCpuUtilization\x12\x1d\n" +
	"\n" +
	"target_qps\x18\x05 \x01(\x05R\ttargetQps\"\xc4\x01\n" +
	"\x11HealthCheckConfig\x122\n" +
	"\x15initial_delay_seconds\x18\x01 \x01(\x05R\x13initialDelaySeconds\x12%\n" +
	"\x0eperiod_seconds\x18\x02 \x01(\x05R\rperiodSeconds\x12'\n" +
	"\x0ftimeout_seconds\x18\x03 \x01(\x05R\x0etimeoutSeconds\x12+\n" +
	"\x11failure_threshold\x18\x04 \x01(\x05R\x10failureThreshold\"\x84\x01\n" +
	"\x13DeployModelResponse\x12.\n" +
	"\x05model\x18\x01 \x01(\v2\x18.openeeap.model.v1.ModelR\x05model\x12#\n" +
	"\rdeployment_id\x18\x02 \x01(\tR\fdeploymentId\x12\x18\n" +
	"\amessage\x18\x03 \x01(\tR\amessage\"O\n" +
	"\x14UndeployModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12'\n" +
	"\x0ftimeout_seconds\x18\x02 \x01(\x05R\x0etimeoutSeconds\"K\n" +
	"\x15UndeployModelResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\"\xbd\x01\n" +
	"\x16GetModelMetricsRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x129\n" +
	"\n" +
	"start_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x12!\n" +
	"\fmetric_names\x18\x04 \x03(\tR\vmetricNames\"T\n" +
	"\x17GetModelMetricsResponse\x129\n" +
	"\ametrics\x18\x01 \x01(\v2\x1f.openeeap.model.v1.ModelMetricsR\ametrics\"\xba\x05\n" +
	"\fModelMetrics\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\x128\n" +
	"\ttimestamp\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\x12\x10\n" +
	"\x03qps\x18\x03 \x01(\x01R\x03qps\x12*\n" +
	"\x11tokens_per_second\x18\x04 \x01(\x01R\x0ftokensPerSecond\x12\x1f\n" +
	"\vavg_latency\x18\x05 \x01(\x01R\n" +
	"avgLatency\x12\x1f\n" +
	"\vp50_latency\x18\x06 \x01(\x01R\n" +
	"p50Latency\x12\x1f\n" +
	"\vp95_latency\x18\a \x01(\x01R\n" +
	"p95Latency\x12\x1f\n" +
	"\vp99_latency\x18\b \x01(\x01R\n" +
	"p99Latency\x12'\n" +
	"\x0fgpu_utilization\x18\t \x01(\x02R\x0egpuUtilization\x124\n" +
	"\x16gpu_memory_utilization\x18\n" +
	" \x01(\x02R\x14gpuMemoryUtilization\x12'\n" +
	"\x0fcpu_utilization\x18\v \x01(\x02R\x0ecpuUtilization\x12-\n" +
	"\x12memory_utilization\x18\f \x01(\x02R\x11memoryUtilization\x12$\n" +
	"\x0ecache_hit_rate\x18\r \x01(\x01R\fcacheHitRate\x12\x1d\n" +
	"\n" +
	"error_rate\x18\x0e \x01(\x01R\terrorRate\x12%\n" +
	"\x0etotal_requests\x18\x0f \x01(\x03R\rtotalRequests\x12'\n" +
	"\x0ffailed_requests\x18\x10 \x01(\x03R\x0efailedRequests\x12\x1d\n" +
	"\n" +
	"total_cost\x18\x11 \x01(\x01R\ttotalCost\x12(\n" +
	"\x10cost_per_request\x18\x12 \x01(\x01R\x0ecostPerRequest\"y\n" +
	"\x19StreamModelMetricsRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12)\n" +
	"\x10interval_seconds\x18\x02 \x01(\x05R\x0fintervalSeconds\x12!\n" +
	"\fmetric_names\x18\x03 \x03(\tR\vmetricNames\"N\n" +
	"\x11ModelMetricsEvent\x129\n" +
	"\ametrics\x18\x01 \x01(\v2\x1f.openeeap.model.v1.ModelMetricsR\ametrics\"$\n" +
	"\x12HealthCheckRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\"\xb0\x02\n" +
	"\x13HealthCheckResponse\x12\x18\n" +
	"\ahealthy\x18\x01 \x01(\bR\ahealthy\x12\x16\n" +
	"\x06status\x18\x02 \x01(\tR\x06status\x12\x18\n" +
	"\amessage\x18\x03 \x01(\tR\amessage\x12M\n" +
	"\adetails\x18\x04 \x03(\v23.openeeap.model.v1.HealthCheckResponse.DetailsEntryR\adetails\x12B\n" +
	"\x0flast_check_time\x18\x05 \x01(\v2\x1a.google.protobuf.TimestampR\rlastCheckTime\x1a:\n" +
	"\fDetailsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\x95\x01\n" +
	"\x14ValidateModelRequest\x126\n" +
	"\x06config\x18\x01 \x01(\v2\x1e.openeeap.model.v1.ModelConfigR\x06config\x12E\n" +
	"\tresources\x18\x02 \x01(\v2'.openeeap.model.v1.ResourceRequirementsR\tresources\"\x85\x01\n" +
	"\x15ValidateModelResponse\x12\x14\n" +
	"\x05valid\x18\x01 \x01(\bR\x05valid\x12:\n" +
	"\x06errors\x18\x02 \x03(\v2\".openeeap.model.v1.ValidationErrorR\x06errors\x12\x1a\n" +
	"\bwarnings\x18\x03 \x03(\tR\bwarnings\"U\n" +
	"\x0fValidationError\x12\x14\n" +
	"\x05field\x18\x01 \x01(\tR\x05field\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12\x12\n" +
	"\x04code\x18\x03 \x01(\tR\x04code*\xbb\x01\n" +
	"\tModelType\x12\x1a\n" +
	"\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\x12\n" +
	"\x0eMODEL_TYPE_LLM\x10\x01\x12\x18\n" +
	"\x14MODEL_TYPE_EMBEDDING\x10\x02\x12\x17\n" +
	"\x13MODEL_TYPE_RERANKER\x10\x03\x12\x19\n" +
	"\x15MODEL_TYPE_CLASSIFIER\x10\x04\x12\x15\n" +
	"\x11MODEL_TYPE_VISION\x10\x05\x12\x19\n" +
	"\x15MODEL_TYPE_MULTIMODAL\x10\x06*\x9c\x02\n" +
	"\x10DeploymentStatus\x12!\n" +
	"\x1dDEPLOYMENT_STATUS_UNSPECIFIED\x10\x00\x12 \n" +
	"\x1cDEPLOYMENT_STATUS_REGISTERED\x10\x01\x12\x1f\n" +
	"\x1bDEPLOYMENT_STATUS_DEPLOYING\x10\x02\x12\x1e\n" +
	"\x1aDEPLOYMENT_STATUS_DEPLOYED\x10\x03\x12\x1c\n" +
	"\x18DEPLOYMENT_STATUS_FAILED\x10\x04\x12!\n" +
	"\x1dDEPLOYMENT_STATUS_UNDEPLOYING\x10\x05\x12 \n" +
	"\x1cDEPLOYMENT_STATUS_UNDEPLOYED\x10\x06\x12\x1f\n" +
	"\x1bDEPLOYMENT_STATUS_UNHEALTHY\x10\a2\xb8\b\n" +
	"\fModelService\x12b\n" +
	"\rRegisterModel\x12'.openeeap.model.v1.RegisterModelRequest\x1a(.openeeap.model.v1.RegisterModelResponse\x12S\n" +
	"\bGetModel\x12\".openeeap.model.v1.GetModelRequest\x1a#.openeeap.model.v1.GetModelResponse\x12Y\n" +
	"\n" +
	"ListModels\x12$.openeeap.model.v1.ListModelsRequest\x1a%.openeeap.model.v1.ListModelsResponse\x12\\\n" +
	"\vUpdateModel\x12%.openeeap.model.v1.UpdateModelRequest\x1a&.openeeap.model.v1.UpdateModelResponse\x12\\\n" +
	"\vDeleteModel\x12%.openeeap.model.v1.DeleteModelRequest\x1a&.openeeap.model.v1.DeleteModelResponse\x12\\\n" +
	"\vDeployModel\x12%.openeeap.model.v1.DeployModelRequest\x1a&.openeeap.model.v1.DeployModelResponse\x12b\n" +
	"\rUndeployModel\x12'.openeeap.model.v1.UndeployModelRequest\x1a(.openeeap.model.v1.UndeployModelResponse\x12h\n" +
	"\x0fGetModelMetrics\x12).openeeap.model.v1.GetModelMetricsRequest\x1a*.openeeap.model.v1.GetModelMetricsResponse\x12j\n" +
	"\x12StreamModelMetrics\x12,.openeeap.model.v1.StreamModelMetricsRequest\x1a$.openeeap.model.v1.ModelMetricsEvent0\x01\x12\\\n" +
	"\vHealthCheck\x12%.openeeap.model.v1.HealthCheckRequest\x1a&.openeeap.model.v1.HealthCheckResponse\x12b\n" +
	"\rValidateModel\x12'.openeeap.model.v1.ValidateModelRequest\x1a(.openeeap.model.v1.ValidateModelResponseB6Z4github.com/openeeap/openeeap/api/proto/model;modelpbb\x06proto3"

var (
	file_model_proto_rawDescOnce sync.Once
	file_model_proto_rawDescData []byte
)

func file_model_proto_rawDescGZIP() []byte {
	file_model_proto_rawDescOnce.Do(func() {
		file_model_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_model_proto_rawDesc), len(file_model_proto_rawDesc)))
	})
	return file_model_proto_rawDescData
}

var file_model_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
var file_model_proto_msgTypes = make([]protoimpl.MessageInfo, 40)
var file_model_proto_goTypes = []any{
	(ModelType)(0),                    // 0: openeeap.model.v1.ModelType
	(DeploymentStatus)(0),             // 1: openeeap.model.v1.DeploymentStatus
	(*Model)(nil),                     // 2: openeeap.model.v1.Model
	(*ModelConfig)(nil),               // 3: openeeap.model.v1.ModelConfig
	(*InferenceConfig)(nil),           // 4: openeeap.model.v1.InferenceConfig
	(*QuantizationConfig)(nil),        // 5: openeeap.model.v1.QuantizationConfig
	(*TokenizerConfig)(nil),           // 6: openeeap.model.v1.TokenizerConfig
	(*ModelCapabilities)(nil),         // 7: openeeap.model.v1.ModelCapabilities
	(*ResourceRequirements)(nil),      // 8: openeeap.model.v1.ResourceRequirements
	(*RegisterModelRequest)(nil),      // 9: openeeap.model.v1.RegisterModelRequest
	(*RegisterModelResponse)(nil),     // 10: openeeap.model.v1.RegisterModelResponse
	(*GetModelRequest)(nil),           // 11: openeeap.model.v1.GetModelRequest
	(*GetModelResponse)(nil),          // 12: openeeap.model.v1.GetModelResponse
	(*ListModelsRequest)(nil),         // 13: openeeap.model.v1.ListModelsRequest
	(*ListModelsResponse)(nil),        // 14: openeeap.model.v1.ListModelsResponse
	(*UpdateModelRequest)(nil),        // 15: openeeap.model.v1.UpdateModelRequest
	(*UpdateModelResponse)(nil),       // 16: openeeap.model.v1.UpdateModelResponse
	(*DeleteModelRequest)(nil),        // 17: openeeap.model.v1.DeleteModelRequest
	(*DeleteModelResponse)(nil),       // 18: openeeap.model.v1.DeleteModelResponse
	(*DeployModelRequest)(nil),        // 19: openeeap.model.v1.DeployModelRequest
	(*DeploymentConfig)(nil),          // 20: openeeap.model.v1.DeploymentConfig
	(*ResourceAllocation)(nil),        // 21: openeeap.model.v1.ResourceAllocation
	(*AutoScalingConfig)(nil),         // 22: openeeap.model.v1.AutoScalingConfig
	(*HealthCheckConfig)(nil),         // 23: openeeap.model.v1.HealthCheckConfig
	(*DeployModelResponse)(nil),       // 24: openeeap.model.v1.DeployModelResponse
	(*UndeployModelRequest)(nil),      // 25: openeeap.model.v1.UndeployModelRequest
	(*UndeployModelResponse)(nil),     // 26: openeeap.model.v1.UndeployModelResponse
	(*GetModelMetricsRequest)(nil),    // 27: openeeap.model.v1.GetModelMetricsRequest
	(*GetModelMetricsResponse)(nil),   // 28: openeeap.model.v1.GetModelMetricsResponse
	(*ModelMetrics)(nil),              // 29: openeeap.model.v1.ModelMetrics
	(*StreamModelMetricsRequest)(nil), // 30: openeeap.model.v1.StreamModelMetricsRequest
	(*ModelMetricsEvent)(nil),         // 31: openeeap.model.v1.ModelMetricsEvent
	(*HealthCheckRequest)(nil),        // 32: openeeap.model.v1.HealthCheckRequest
	(*HealthCheckResponse)(nil),       // 33: openeeap.model.v1.HealthCheckResponse
	(*ValidateModelRequest)(nil),      // 34: openeeap.model.v1.ValidateModelRequest
	(*ValidateModelResponse)(nil),     // 35: openeeap.model.v1.ValidateModelResponse
	(*ValidationError)(nil),           // 36: openeeap.model.v1.ValidationError
	nil,                               // 37: openeeap.model.v1.Model.MetadataEntry
	nil,                               // 38: openeeap.model.v1.TokenizerConfig.SpecialTokensEntry
	nil,                               // 39: openeeap.model.v1.RegisterModelRequest.MetadataEntry
	nil,                               // 40: openeeap.model.v1.UpdateModelRequest.MetadataEntry
	nil,                               // 41: openeeap.model.v1.HealthCheckResponse.DetailsEntry
	(*timestamppb.Timestamp)(nil),     // 42: google.protobuf.Timestamp
	(*structpb.Struct)(nil),           // 43: google.protobuf.Struct
}
var file_model_proto_depIdxs = []int32{
	0,  // 0: openeeap.model.v1.Model.type:type_name -> openeeap.model.v1.ModelType
	3,  // 1: openeeap.model.v1.Model.config:type_name -> openeeap.model.v1.ModelConfig
	7,  // 2: openeeap.model.v1.Model.capabilities:type_name -> openeeap.model.v1.ModelCapabilities
	8,  // 3: openeeap.model.v1.Model.resources:type_name -> openeeap.model.v1.ResourceRequirements
	1,  // 4: openeeap.model.v1.Model.status:type_name -> openeeap.model.v1.DeploymentStatus
	37, // 5: openeeap.model.v1.Model.metadata:type_name -> openeeap.model.v1.Model.MetadataEntry
	42, // 6: openeeap.model.v1.Model.created_at:type_name -> google.protobuf.Timestamp
	42, // 7: openeeap.model.v1.Model.updated_at:type_name -> google.protobuf.Timestamp
	4,  // 8: openeeap.model.v1.ModelConfig.inference_config:type_name -> openeeap.model.v1.InferenceConfig
	5,  // 9: openeeap.model.v1.ModelConfig.quantization:type_name -> openeeap.model.v1.QuantizationConfig
	6,  // 10: openeeap.model.v1.ModelConfig.tokenizer:type_name -> openeeap.model.v1.TokenizerConfig
	43, // 11: openeeap.model.v1.ModelConfig.custom_config:type_name -> google.protobuf.Struct
	38, // 12: openeeap.model.v1.TokenizerConfig.special_tokens:type_name -> openeeap.model.v1.TokenizerConfig.SpecialTokensEntry
	0,  // 13: openeeap.model.v1.RegisterModelRequest.type:type_name -> openeeap.model.v1.ModelType
	3,  // 14: openeeap.model.v1.RegisterModelRequest.config:type_name -> openeeap.model.v1.ModelConfig
	7,  // 15: openeeap.model.v1.RegisterModelRequest.capabilities:type_name -> openeeap.model.v1.ModelCapabilities
	8,  // 16: openeeap.model.v1.RegisterModelRequest.resources:type_name -> openeeap.model.v1.ResourceRequirements
	39, // 17: openeeap.model.v1.RegisterModelRequest.metadata:type_name -> openeeap.model.v1.RegisterModelRequest.MetadataEntry
	2,  // 18: openeeap.model.v1.RegisterModelResponse.model:type_name -> openeeap.model.v1.Model
	2,  // 19: openeeap.model.v1.GetModelResponse.model:type_name -> openeeap.model.v1.Model
	0,  // 20: openeeap.model.v1.ListModelsRequest.type:type_name -> openeeap.model.v1.ModelType
	1,  // 21: openeeap.model.v1.ListModelsRequest.status:type_name -> openeeap.model.v1.DeploymentStatus
	2,  // 22: openeeap.model.v1.ListModelsResponse.models:type_name -> openeeap.model.v1.Model
	3,  // 23: openeeap.model.v1.UpdateModelRequest.config:type_name -> openeeap.model.v1.ModelConfig
	40, // 24: openeeap.model.v1.UpdateModelRequest.metadata:type_name -> openeeap.model.v1.UpdateModelRequest.MetadataEntry
	2,  // 25: openeeap.model.v1.UpdateModelResponse.model:type_name -> openeeap.model.v1.Model
	20, // 26: openeeap.model.v1.DeployModelRequest.deployment_config:type_name -> openeeap.model.v1.DeploymentConfig
	21, // 27: openeeap.model.v1.DeploymentConfig.resource_allocation:type_name -> openeeap.model.v1.ResourceAllocation
	22, // 28: openeeap.model.v1.DeploymentConfig.auto_scaling:type_name -> openeeap.model.v1.AutoScalingConfig
	23, // 29: openeeap.model.v1.DeploymentConfig.health_check:type_name -> openeeap.model.v1.HealthCheckConfig
	2,  // 30: openeeap.model.v1.DeployModelResponse.model:type_name -> openeeap.model.v1.Model
	42, // 31: openeeap.model.v1.GetModelMetricsRequest.start_time:type_name -> google.protobuf.Timestamp
	42, // 32: openeeap.model.v1.GetModelMetricsRequest.end_time:type_name -> google.protobuf.Timestamp
	29, // 33: openeeap.model.v1.GetModelMetricsResponse.metrics:type_name -> openeeap.model.v1.ModelMetrics
	42, // 34: openeeap.model.v1.ModelMetrics.timestamp:type_name -> google.protobuf.Timestamp
	29, // 35: openeeap.model.v1.ModelMetricsEvent.metrics:type_name -> openeeap.model.v1.ModelMetrics
	41, // 36: openeeap.model.v1.HealthCheckResponse.details:type_name -> openeeap.model.v1.HealthCheckResponse.DetailsEntry
	42, // 37: openeeap.model.v1.HealthCheckResponse.last_check_time:type_name -> google.protobuf.Timestamp
	3,  // 38: openeeap.model.v1.ValidateModelRequest.config:type_name -> openeeap.model.v1.ModelConfig
	8,  // 39: openeeap.model.v1.ValidateModelRequest.resources:type_name -> openeeap.model.v1.ResourceRequirements
	36, // 40: openeeap.model.v1.ValidateModelResponse.errors:type_name -> openeeap.model.v1.ValidationError
	9,  // 41: openeeap.model.v1.ModelService.RegisterModel:input_type -> openeeap.model.v1.RegisterModelRequest
	11, // 42: openeeap.model.v1.ModelService.GetModel:input_type -> openeeap.model.v1.GetModelRequest
	13, // 43: openeeap.model.v1.ModelService.ListModels:input_type -> openeeap.model.v1.ListModelsRequest
	15, // 44: openeeap.model.v1.ModelService.UpdateModel:input_type -> openeeap.model.v1.UpdateModelRequest
	17, // 45: openeeap.model.v1.ModelService.DeleteModel:input_type -> openeeap.model.v1.DeleteModelRequest
	19, // 46: openeeap.model.v1.ModelService.DeployModel:input_type -> openeeap.model.v1.DeployModelRequest
	25, // 47: openeeap.model.v1.ModelService.UndeployModel:input_type -> openeeap.model.v1.UndeployModelRequest
	27, // 48: openeeap.model.v1.ModelService.GetModelMetrics:input_type -> openeeap.model.v1.GetModelMetricsRequest
	30, // 49: openeeap.model.v1.ModelService.StreamModelMetrics:input_type -> openeeap.model.v1.StreamModelMetricsRequest
	32, // 50: openeeap.model.v1.ModelService.HealthCheck:input_type -> openeeap.model.v1.HealthCheckRequest
	34, // 51: openeeap.model.v1.ModelService.ValidateModel:input_type -> openeeap.model.v1.ValidateModelRequest
	10, // 52: openeeap.model.v1.ModelService.RegisterModel:output_type -> openeeap.model.v1.RegisterModelResponse
	12, // 53: openeeap.model.v1.ModelService.GetModel:output_type -> openeeap.model.v1.GetModelResponse
	14, // 54: openeeap.model.v1.ModelService.ListModels:output_type -> openeeap.model.v1.ListModelsResponse
	16, // 55: openeeap.model.v1.ModelService.UpdateModel:output_type -> openeeap.model.v1.UpdateModelResponse
	18, // 56: openeeap.model.v1.ModelService.DeleteModel:output_type -> openeeap.model.v1.DeleteModelResponse
	24, // 57: openeeap.model.v1.ModelService.DeployModel:output_type -> openeeap.model.v1.DeployModelResponse
	26, // 58: openeeap.model.v1.ModelService.UndeployModel:output_type -> openeeap.model.v1.UndeployModelResponse
	28, // 59: openeeap.model.v1.ModelService.GetModelMetrics:output_type -> openeeap.model.v1.GetModelMetricsResponse
	31, // 60: openeeap.model.v1.ModelService.StreamModelMetrics:output_type -> openeeap.model.v1.ModelMetricsEvent
	33, // 61: openeeap.model.v1.ModelService.HealthCheck:output_type -> openeeap.model.v1.HealthCheckResponse
	35, // 62: openeeap.model.v1.ModelService.ValidateModel:output_type -> openeeap.model.v1.ValidateModelResponse
	52, // [52:63] is the sub-list for method output_type
	41, // [41:52] is the sub-list for method input_type
	41, // [41:41] is the sub-list for extension type_name
	41, // [41:41] is the sub-list for extension extendee
	0,  // [0:41] is the sub-list for field type_name
}

func init() { file_model_proto_init() }
func file_model_proto_init() {
	if File_model_proto != nil {
		return
	}
	file_model_proto_msgTypes[13].OneofWrappers = []any{}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_model_proto_rawDesc), len(file_model_proto_rawDesc)),
			NumEnums:      2,
			NumMessages:   40,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_model_proto_goTypes,
		DependencyIndexes: file_model_proto_depIdxs,
		EnumInfos:         file_model_proto_enumTypes,
		MessageInfos:      file_model_proto_msgTypes,
	}.Build()
	File_model_proto = out.File
	file_model_proto_goTypes = nil
	file_model_proto_depIdxs = nil
}
